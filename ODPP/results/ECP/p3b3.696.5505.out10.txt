Importing candle utils for keras
Configuration file:  /home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/p3b3_default_model.txt
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'filter_sets': 3,
 'filter_sizes': 3,
 'learning_rate': 0.01,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'train_data': 'P3B3_data.tar.gz',
 'w_l2': 0.01,
 'wv_len': 300}
Params:
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'datatype': <class 'numpy.float32'>,
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'experiment_id': 'EXP000',
 'filter_sets': 3,
 'filter_sizes': 3,
 'gpus': [],
 'learning_rate': 0.01,
 'logfile': None,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'output_dir': '/home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/Output/EXP000/RUN000',
 'rng_seed': 7102,
 'run_id': 'RUN000',
 'shuffle': False,
 'timeout': -1,
 'train_bool': True,
 'train_data': 'P3B3_data.tar.gz',
 'verbose': None,
 'w_l2': 0.01,
 'wv_len': 300}
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input (InputLayer)              (None, 1500)         0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 1500, 300)    1396200     Input[0][0]                      
__________________________________________________________________________________________________
0_thfilter (Conv1D)             (None, 1500, 100)    90100       embedding[0][0]                  
__________________________________________________________________________________________________
1_thfilter (Conv1D)             (None, 1500, 100)    120100      embedding[0][0]                  
__________________________________________________________________________________________________
2_thfilter (Conv1D)             (None, 1500, 100)    150100      embedding[0][0]                  
__________________________________________________________________________________________________
global_max_pooling1d_1 (GlobalM (None, 100)          0           0_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_2 (GlobalM (None, 100)          0           1_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_3 (GlobalM (None, 100)          0           2_thfilter[0][0]                 
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 300)          0           global_max_pooling1d_1[0][0]     
                                                                 global_max_pooling1d_2[0][0]     
                                                                 global_max_pooling1d_3[0][0]     
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 300)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
Dense0 (Dense)                  (None, 6)            1806        dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense1 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense2 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense3 (Dense)                  (None, 3)            903         dropout_1[0][0]                  
==================================================================================================
Total params: 1,760,413
Trainable params: 1,760,413
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 8000 samples, validate on 2000 samples
Epoch 1/10
 - 27s - loss: 17.6747 - Dense0_loss: 2.7254 - Dense1_loss: 1.4668 - Dense2_loss: 1.1412 - Dense3_loss: 4.0918 - Dense0_acc: 0.7376 - Dense1_acc: 0.8442 - Dense2_acc: 0.8929 - Dense3_acc: 0.5993 - val_loss: 22.9726 - val_Dense0_loss: 3.8936 - val_Dense1_loss: 2.5043 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 6.7462 - val_Dense0_acc: 0.7570 - val_Dense1_acc: 0.8425 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.5730
Current time ....26.526
Epoch 2/10
 - 23s - loss: 23.4501 - Dense0_loss: 4.5999 - Dense1_loss: 2.7096 - Dense2_loss: 1.7324 - Dense3_loss: 7.8692 - Dense0_acc: 0.7126 - Dense1_acc: 0.8297 - Dense2_acc: 0.8924 - Dense3_acc: 0.5078 - val_loss: 21.7776 - val_Dense0_loss: 4.3435 - val_Dense1_loss: 1.8858 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.8534 - val_Dense0_acc: 0.7305 - val_Dense1_acc: 0.8830 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4505
Current time ....49.762
Epoch 3/10
 - 23s - loss: 23.2523 - Dense0_loss: 4.9767 - Dense1_loss: 3.6680 - Dense2_loss: 1.7333 - Dense3_loss: 9.0072 - Dense0_acc: 0.6906 - Dense1_acc: 0.7720 - Dense2_acc: 0.8924 - Dense3_acc: 0.4410 - val_loss: 22.2112 - val_Dense0_loss: 4.2638 - val_Dense1_loss: 2.8106 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3485 - val_Dense0_acc: 0.7350 - val_Dense1_acc: 0.8255 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4200
Current time ....73.020
Epoch 4/10
 - 23s - loss: 21.3704 - Dense0_loss: 5.1092 - Dense1_loss: 2.8027 - Dense2_loss: 1.7327 - Dense3_loss: 8.3666 - Dense0_acc: 0.6829 - Dense1_acc: 0.8259 - Dense2_acc: 0.8925 - Dense3_acc: 0.4805 - val_loss: 25.8818 - val_Dense0_loss: 5.7058 - val_Dense1_loss: 6.5198 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9617 - val_Dense0_acc: 0.6460 - val_Dense1_acc: 0.5955 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4440
Current time ....96.240
Epoch 5/10
 - 23s - loss: 24.4861 - Dense0_loss: 5.4882 - Dense1_loss: 6.5017 - Dense2_loss: 1.7327 - Dense3_loss: 8.4783 - Dense0_acc: 0.6590 - Dense1_acc: 0.5966 - Dense2_acc: 0.8925 - Dense3_acc: 0.4739 - val_loss: 23.7856 - val_Dense0_loss: 5.3077 - val_Dense1_loss: 5.9972 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.3592 - val_Dense0_acc: 0.6700 - val_Dense1_acc: 0.6275 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4810
Current time ....119.517
Epoch 6/10
 - 23s - loss: 22.6496 - Dense0_loss: 4.9298 - Dense1_loss: 4.5114 - Dense2_loss: 1.7327 - Dense3_loss: 8.2824 - Dense0_acc: 0.6939 - Dense1_acc: 0.7199 - Dense2_acc: 0.8925 - Dense3_acc: 0.4858 - val_loss: 25.4589 - val_Dense0_loss: 4.2471 - val_Dense1_loss: 6.2861 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.7365 - val_Dense1_acc: 0.6100 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....142.826
Epoch 7/10
 - 23s - loss: 21.1716 - Dense0_loss: 4.6360 - Dense1_loss: 3.4175 - Dense2_loss: 1.7327 - Dense3_loss: 8.6474 - Dense0_acc: 0.7124 - Dense1_acc: 0.7876 - Dense2_acc: 0.8925 - Dense3_acc: 0.4635 - val_loss: 18.8330 - val_Dense0_loss: 4.2955 - val_Dense1_loss: 1.8213 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.7335 - val_Dense1_acc: 0.8870 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....166.115
Epoch 8/10
 - 23s - loss: 19.6039 - Dense0_loss: 5.1078 - Dense1_loss: 2.3309 - Dense2_loss: 1.7327 - Dense3_loss: 8.6474 - Dense0_acc: 0.6829 - Dense1_acc: 0.8554 - Dense2_acc: 0.8925 - Dense3_acc: 0.4635 - val_loss: 19.6940 - val_Dense0_loss: 4.6420 - val_Dense1_loss: 2.1759 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.7120 - val_Dense1_acc: 0.8650 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....189.401
Epoch 9/10
 - 23s - loss: 22.7604 - Dense0_loss: 5.5647 - Dense1_loss: 4.1264 - Dense2_loss: 1.7327 - Dense3_loss: 8.6514 - Dense0_acc: 0.6543 - Dense1_acc: 0.7439 - Dense2_acc: 0.8925 - Dense3_acc: 0.4633 - val_loss: 32.4178 - val_Dense0_loss: 12.2981 - val_Dense1_loss: 6.5681 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.2370 - val_Dense1_acc: 0.5925 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....212.637
Epoch 10/10
 - 23s - loss: 24.5120 - Dense0_loss: 4.8017 - Dense1_loss: 6.9691 - Dense2_loss: 1.7327 - Dense3_loss: 8.6514 - Dense0_acc: 0.7020 - Dense1_acc: 0.5676 - Dense2_acc: 0.8925 - Dense3_acc: 0.4633 - val_loss: 23.0267 - val_Dense0_loss: 4.0859 - val_Dense1_loss: 6.5681 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.7465 - val_Dense1_acc: 0.5925 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....235.926
Return:  <keras.callbacks.History object at 0x7f5571d6fda0>
244663
start time: 05:11:59
