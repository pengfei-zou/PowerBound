Importing candle utils for keras
Configuration file:  /home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/p3b3_default_model.txt
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'filter_sets': 3,
 'filter_sizes': 3,
 'learning_rate': 0.01,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'train_data': 'P3B3_data.tar.gz',
 'w_l2': 0.01,
 'wv_len': 300}
Params:
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'datatype': <class 'numpy.float32'>,
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'experiment_id': 'EXP000',
 'filter_sets': 3,
 'filter_sizes': 3,
 'gpus': [],
 'learning_rate': 0.01,
 'logfile': None,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'output_dir': '/home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/Output/EXP000/RUN000',
 'rng_seed': 7102,
 'run_id': 'RUN000',
 'shuffle': False,
 'timeout': -1,
 'train_bool': True,
 'train_data': 'P3B3_data.tar.gz',
 'verbose': None,
 'w_l2': 0.01,
 'wv_len': 300}
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input (InputLayer)              (None, 1500)         0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 1500, 300)    1396200     Input[0][0]                      
__________________________________________________________________________________________________
0_thfilter (Conv1D)             (None, 1500, 100)    90100       embedding[0][0]                  
__________________________________________________________________________________________________
1_thfilter (Conv1D)             (None, 1500, 100)    120100      embedding[0][0]                  
__________________________________________________________________________________________________
2_thfilter (Conv1D)             (None, 1500, 100)    150100      embedding[0][0]                  
__________________________________________________________________________________________________
global_max_pooling1d_1 (GlobalM (None, 100)          0           0_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_2 (GlobalM (None, 100)          0           1_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_3 (GlobalM (None, 100)          0           2_thfilter[0][0]                 
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 300)          0           global_max_pooling1d_1[0][0]     
                                                                 global_max_pooling1d_2[0][0]     
                                                                 global_max_pooling1d_3[0][0]     
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 300)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
Dense0 (Dense)                  (None, 6)            1806        dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense1 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense2 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense3 (Dense)                  (None, 3)            903         dropout_1[0][0]                  
==================================================================================================
Total params: 1,760,413
Trainable params: 1,760,413
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 8000 samples, validate on 2000 samples
Epoch 1/10
 - 18s - loss: 16.1705 - Dense0_loss: 2.1276 - Dense1_loss: 1.1962 - Dense2_loss: 0.8275 - Dense3_loss: 3.1672 - Dense0_acc: 0.7549 - Dense1_acc: 0.8427 - Dense2_acc: 0.9022 - Dense3_acc: 0.6181 - val_loss: 26.2135 - val_Dense0_loss: 3.1019 - val_Dense1_loss: 1.5128 - val_Dense2_loss: 1.8056 - val_Dense3_loss: 8.3023 - val_Dense0_acc: 0.8020 - val_Dense1_acc: 0.9020 - val_Dense2_acc: 0.8860 - val_Dense3_acc: 0.4740
Current time ....18.018
Epoch 2/10
 - 15s - loss: 27.6254 - Dense0_loss: 5.0138 - Dense1_loss: 3.3010 - Dense2_loss: 1.6965 - Dense3_loss: 8.9926 - Dense0_acc: 0.6856 - Dense1_acc: 0.7916 - Dense2_acc: 0.8932 - Dense3_acc: 0.4381 - val_loss: 29.7075 - val_Dense0_loss: 11.4022 - val_Dense1_loss: 1.5741 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3470 - val_Dense0_acc: 0.2905 - val_Dense1_acc: 0.8995 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4195
Current time ....32.693
Epoch 3/10
 - 15s - loss: 22.4265 - Dense0_loss: 4.4822 - Dense1_loss: 2.1509 - Dense2_loss: 1.7333 - Dense3_loss: 9.5016 - Dense0_acc: 0.7208 - Dense1_acc: 0.8654 - Dense2_acc: 0.8924 - Dense3_acc: 0.4099 - val_loss: 20.5242 - val_Dense0_loss: 3.9611 - val_Dense1_loss: 2.1840 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3566 - val_Dense0_acc: 0.7540 - val_Dense1_acc: 0.8645 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4195
Current time ....47.300
Epoch 4/10
 - 15s - loss: 22.8619 - Dense0_loss: 4.4236 - Dense1_loss: 4.1496 - Dense2_loss: 1.7327 - Dense3_loss: 9.5068 - Dense0_acc: 0.7249 - Dense1_acc: 0.7421 - Dense2_acc: 0.8925 - Dense3_acc: 0.4100 - val_loss: 24.6018 - val_Dense0_loss: 4.0134 - val_Dense1_loss: 6.3748 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3566 - val_Dense0_acc: 0.7510 - val_Dense1_acc: 0.6045 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4195
Current time ....61.946
Epoch 5/10
 - 15s - loss: 22.4115 - Dense0_loss: 4.1229 - Dense1_loss: 4.2912 - Dense2_loss: 1.7347 - Dense3_loss: 9.5152 - Dense0_acc: 0.7441 - Dense1_acc: 0.7331 - Dense2_acc: 0.8924 - Dense3_acc: 0.4095 - val_loss: 20.0479 - val_Dense0_loss: 4.2345 - val_Dense1_loss: 2.1115 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3566 - val_Dense0_acc: 0.7370 - val_Dense1_acc: 0.8690 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4195
Current time ....76.562
Epoch 6/10
 - 15s - loss: 21.0430 - Dense0_loss: 5.2123 - Dense1_loss: 2.3384 - Dense2_loss: 1.7327 - Dense3_loss: 9.5077 - Dense0_acc: 0.6765 - Dense1_acc: 0.8546 - Dense2_acc: 0.8925 - Dense3_acc: 0.4101 - val_loss: 20.3635 - val_Dense0_loss: 5.1096 - val_Dense1_loss: 2.1679 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3566 - val_Dense0_acc: 0.6830 - val_Dense1_acc: 0.8655 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4195
Current time ....91.158
Epoch 7/10
 - 15s - loss: 22.1474 - Dense0_loss: 5.5772 - Dense1_loss: 2.9379 - Dense2_loss: 1.7347 - Dense3_loss: 9.5064 - Dense0_acc: 0.6536 - Dense1_acc: 0.8175 - Dense2_acc: 0.8924 - Dense3_acc: 0.4100 - val_loss: 20.7536 - val_Dense0_loss: 4.2149 - val_Dense1_loss: 2.2888 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3566 - val_Dense0_acc: 0.7385 - val_Dense1_acc: 0.8580 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4195
Current time ....105.803
Epoch 8/10
 - 15s - loss: 20.7324 - Dense0_loss: 4.6863 - Dense1_loss: 2.6263 - Dense2_loss: 1.7327 - Dense3_loss: 9.5111 - Dense0_acc: 0.7093 - Dense1_acc: 0.8369 - Dense2_acc: 0.8925 - Dense3_acc: 0.4099 - val_loss: 19.8023 - val_Dense0_loss: 4.5211 - val_Dense1_loss: 2.3814 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3566 - val_Dense0_acc: 0.7195 - val_Dense1_acc: 0.8515 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4195
Current time ....120.432
Epoch 9/10
 - 15s - loss: 19.8397 - Dense0_loss: 5.1026 - Dense1_loss: 2.1830 - Dense2_loss: 1.7347 - Dense3_loss: 9.5077 - Dense0_acc: 0.6834 - Dense1_acc: 0.8645 - Dense2_acc: 0.8924 - Dense3_acc: 0.4101 - val_loss: 19.7028 - val_Dense0_loss: 4.7054 - val_Dense1_loss: 2.1763 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3566 - val_Dense0_acc: 0.7080 - val_Dense1_acc: 0.8645 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4195
Current time ....135.053
Epoch 10/10
 - 15s - loss: 22.1367 - Dense0_loss: 4.4173 - Dense1_loss: 4.6233 - Dense2_loss: 1.7327 - Dense3_loss: 9.5077 - Dense0_acc: 0.7259 - Dense1_acc: 0.7128 - Dense2_acc: 0.8925 - Dense3_acc: 0.4101 - val_loss: 21.1547 - val_Dense0_loss: 4.5477 - val_Dense1_loss: 3.1328 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3566 - val_Dense0_acc: 0.7175 - val_Dense1_acc: 0.8050 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4195
Current time ....149.701
Return:  <keras.callbacks.History object at 0x7f117dcf8dd8>
158422
start time: 03:54:21
