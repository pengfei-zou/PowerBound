Importing candle utils for keras
Configuration file:  /home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/p3b3_default_model.txt
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'filter_sets': 3,
 'filter_sizes': 3,
 'learning_rate': 0.01,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'train_data': 'P3B3_data.tar.gz',
 'w_l2': 0.01,
 'wv_len': 300}
Params:
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'datatype': <class 'numpy.float32'>,
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'experiment_id': 'EXP000',
 'filter_sets': 3,
 'filter_sizes': 3,
 'gpus': [],
 'learning_rate': 0.01,
 'logfile': None,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'output_dir': '/home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/Output/EXP000/RUN000',
 'rng_seed': 7102,
 'run_id': 'RUN000',
 'shuffle': False,
 'timeout': -1,
 'train_bool': True,
 'train_data': 'P3B3_data.tar.gz',
 'verbose': None,
 'w_l2': 0.01,
 'wv_len': 300}
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input (InputLayer)              (None, 1500)         0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 1500, 300)    1396200     Input[0][0]                      
__________________________________________________________________________________________________
0_thfilter (Conv1D)             (None, 1500, 100)    90100       embedding[0][0]                  
__________________________________________________________________________________________________
1_thfilter (Conv1D)             (None, 1500, 100)    120100      embedding[0][0]                  
__________________________________________________________________________________________________
2_thfilter (Conv1D)             (None, 1500, 100)    150100      embedding[0][0]                  
__________________________________________________________________________________________________
global_max_pooling1d_1 (GlobalM (None, 100)          0           0_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_2 (GlobalM (None, 100)          0           1_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_3 (GlobalM (None, 100)          0           2_thfilter[0][0]                 
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 300)          0           global_max_pooling1d_1[0][0]     
                                                                 global_max_pooling1d_2[0][0]     
                                                                 global_max_pooling1d_3[0][0]     
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 300)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
Dense0 (Dense)                  (None, 6)            1806        dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense1 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense2 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense3 (Dense)                  (None, 3)            903         dropout_1[0][0]                  
==================================================================================================
Total params: 1,760,413
Trainable params: 1,760,413
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 8000 samples, validate on 2000 samples
Epoch 1/10
 - 45s - loss: 17.0019 - Dense0_loss: 2.3085 - Dense1_loss: 1.3135 - Dense2_loss: 0.8467 - Dense3_loss: 2.9198 - Dense0_acc: 0.7442 - Dense1_acc: 0.8421 - Dense2_acc: 0.9075 - Dense3_acc: 0.6390 - val_loss: 23.8808 - val_Dense0_loss: 3.1396 - val_Dense1_loss: 1.5885 - val_Dense2_loss: 1.7919 - val_Dense3_loss: 4.9473 - val_Dense0_acc: 0.7930 - val_Dense1_acc: 0.8860 - val_Dense2_acc: 0.8860 - val_Dense3_acc: 0.6715
Current time ....45.139
Epoch 2/10
 - 41s - loss: 26.7545 - Dense0_loss: 4.7436 - Dense1_loss: 2.9993 - Dense2_loss: 1.9595 - Dense3_loss: 8.2536 - Dense0_acc: 0.7006 - Dense1_acc: 0.8080 - Dense2_acc: 0.8764 - Dense3_acc: 0.4809 - val_loss: 25.0967 - val_Dense0_loss: 3.8723 - val_Dense1_loss: 3.5784 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.1923 - val_Dense0_acc: 0.7590 - val_Dense1_acc: 0.7750 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4280
Current time ....86.626
Epoch 3/10
 - 42s - loss: 25.8271 - Dense0_loss: 4.4887 - Dense1_loss: 6.1832 - Dense2_loss: 1.7327 - Dense3_loss: 8.4836 - Dense0_acc: 0.7209 - Dense1_acc: 0.6160 - Dense2_acc: 0.8925 - Dense3_acc: 0.4725 - val_loss: 24.8583 - val_Dense0_loss: 4.2955 - val_Dense1_loss: 6.5750 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 7.8860 - val_Dense0_acc: 0.7335 - val_Dense1_acc: 0.5920 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.5105
Current time ....128.139
Epoch 4/10
 - 42s - loss: 25.9770 - Dense0_loss: 4.8801 - Dense1_loss: 6.2591 - Dense2_loss: 1.7366 - Dense3_loss: 9.0824 - Dense0_acc: 0.6969 - Dense1_acc: 0.6113 - Dense2_acc: 0.8922 - Dense3_acc: 0.4359 - val_loss: 29.1884 - val_Dense0_loss: 4.2229 - val_Dense1_loss: 9.4622 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3404 - val_Dense0_acc: 0.7380 - val_Dense1_acc: 0.4125 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4205
Current time ....169.681
Epoch 5/10
 - 42s - loss: 24.9374 - Dense0_loss: 4.3888 - Dense1_loss: 5.9576 - Dense2_loss: 1.7327 - Dense3_loss: 9.5096 - Dense0_acc: 0.7275 - Dense1_acc: 0.6300 - Dense2_acc: 0.8925 - Dense3_acc: 0.4100 - val_loss: 21.4374 - val_Dense0_loss: 4.0537 - val_Dense1_loss: 3.3848 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3566 - val_Dense0_acc: 0.7485 - val_Dense1_acc: 0.7900 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4195
Current time ....211.228
Epoch 6/10
 - 42s - loss: 24.0574 - Dense0_loss: 4.4348 - Dense1_loss: 5.5441 - Dense2_loss: 1.7327 - Dense3_loss: 9.5117 - Dense0_acc: 0.7246 - Dense1_acc: 0.6556 - Dense2_acc: 0.8925 - Dense3_acc: 0.4099 - val_loss: 20.8182 - val_Dense0_loss: 4.3047 - val_Dense1_loss: 2.8565 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3308 - val_Dense0_acc: 0.7325 - val_Dense1_acc: 0.8220 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4210
Current time ....252.789
Epoch 7/10
 - 42s - loss: 22.2964 - Dense0_loss: 5.7380 - Dense1_loss: 2.9271 - Dense2_loss: 1.7347 - Dense3_loss: 9.5258 - Dense0_acc: 0.6440 - Dense1_acc: 0.8181 - Dense2_acc: 0.8924 - Dense3_acc: 0.4090 - val_loss: 21.8748 - val_Dense0_loss: 5.9323 - val_Dense1_loss: 1.8400 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3566 - val_Dense0_acc: 0.6315 - val_Dense1_acc: 0.8855 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4195
Current time ....294.305
Epoch 8/10
 - 42s - loss: 22.5755 - Dense0_loss: 5.8482 - Dense1_loss: 2.8015 - Dense2_loss: 1.7327 - Dense3_loss: 9.5036 - Dense0_acc: 0.6370 - Dense1_acc: 0.8256 - Dense2_acc: 0.8925 - Dense3_acc: 0.4104 - val_loss: 24.3985 - val_Dense0_loss: 6.9970 - val_Dense1_loss: 2.2243 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3566 - val_Dense0_acc: 0.5650 - val_Dense1_acc: 0.8620 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4195
Current time ....335.849
Epoch 9/10
 - 42s - loss: 23.3122 - Dense0_loss: 6.9909 - Dense1_loss: 2.4489 - Dense2_loss: 1.7327 - Dense3_loss: 9.5077 - Dense0_acc: 0.5663 - Dense1_acc: 0.8480 - Dense2_acc: 0.8925 - Dense3_acc: 0.4101 - val_loss: 27.2100 - val_Dense0_loss: 7.1000 - val_Dense1_loss: 6.3989 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3566 - val_Dense0_acc: 0.5595 - val_Dense1_acc: 0.6030 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4195
Current time ....377.414
Epoch 10/10
 - 42s - loss: 24.9425 - Dense0_loss: 6.6573 - Dense1_loss: 3.8718 - Dense2_loss: 1.7327 - Dense3_loss: 9.5077 - Dense0_acc: 0.5869 - Dense1_acc: 0.7595 - Dense2_acc: 0.8925 - Dense3_acc: 0.4101 - val_loss: 22.6622 - val_Dense0_loss: 6.8985 - val_Dense1_loss: 1.7408 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3566 - val_Dense0_acc: 0.5720 - val_Dense1_acc: 0.8920 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4195
Current time ....418.963
Return:  <keras.callbacks.History object at 0x7f88523dea20>
427728
start time: 01:50:39
