Importing candle utils for keras
Configuration file:  /home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/p3b3_default_model.txt
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'filter_sets': 3,
 'filter_sizes': 3,
 'learning_rate': 0.01,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'train_data': 'P3B3_data.tar.gz',
 'w_l2': 0.01,
 'wv_len': 300}
Params:
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'datatype': <class 'numpy.float32'>,
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'experiment_id': 'EXP000',
 'filter_sets': 3,
 'filter_sizes': 3,
 'gpus': [],
 'learning_rate': 0.01,
 'logfile': None,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'output_dir': '/home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/Output/EXP000/RUN000',
 'rng_seed': 7102,
 'run_id': 'RUN000',
 'shuffle': False,
 'timeout': -1,
 'train_bool': True,
 'train_data': 'P3B3_data.tar.gz',
 'verbose': None,
 'w_l2': 0.01,
 'wv_len': 300}
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input (InputLayer)              (None, 1500)         0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 1500, 300)    1396200     Input[0][0]                      
__________________________________________________________________________________________________
0_thfilter (Conv1D)             (None, 1500, 100)    90100       embedding[0][0]                  
__________________________________________________________________________________________________
1_thfilter (Conv1D)             (None, 1500, 100)    120100      embedding[0][0]                  
__________________________________________________________________________________________________
2_thfilter (Conv1D)             (None, 1500, 100)    150100      embedding[0][0]                  
__________________________________________________________________________________________________
global_max_pooling1d_1 (GlobalM (None, 100)          0           0_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_2 (GlobalM (None, 100)          0           1_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_3 (GlobalM (None, 100)          0           2_thfilter[0][0]                 
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 300)          0           global_max_pooling1d_1[0][0]     
                                                                 global_max_pooling1d_2[0][0]     
                                                                 global_max_pooling1d_3[0][0]     
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 300)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
Dense0 (Dense)                  (None, 6)            1806        dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense1 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense2 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense3 (Dense)                  (None, 3)            903         dropout_1[0][0]                  
==================================================================================================
Total params: 1,760,413
Trainable params: 1,760,413
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 8000 samples, validate on 2000 samples
Epoch 1/10
 - 20s - loss: 17.2775 - Dense0_loss: 2.7737 - Dense1_loss: 1.4148 - Dense2_loss: 1.1773 - Dense3_loss: 4.0525 - Dense0_acc: 0.7344 - Dense1_acc: 0.8450 - Dense2_acc: 0.8896 - Dense3_acc: 0.5914 - val_loss: 22.8891 - val_Dense0_loss: 3.9600 - val_Dense1_loss: 1.5401 - val_Dense2_loss: 1.5062 - val_Dense3_loss: 6.5096 - val_Dense0_acc: 0.7515 - val_Dense1_acc: 0.8945 - val_Dense2_acc: 0.9055 - val_Dense3_acc: 0.5860
Current time ....19.513
Epoch 2/10
 - 16s - loss: 24.3180 - Dense0_loss: 4.7212 - Dense1_loss: 2.9871 - Dense2_loss: 1.6851 - Dense3_loss: 8.2619 - Dense0_acc: 0.7044 - Dense1_acc: 0.8102 - Dense2_acc: 0.8946 - Dense3_acc: 0.4831 - val_loss: 22.5230 - val_Dense0_loss: 4.0456 - val_Dense1_loss: 1.7376 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.2688 - val_Dense0_acc: 0.7490 - val_Dense1_acc: 0.8880 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4235
Current time ....35.392
Epoch 3/10
 - 16s - loss: 22.8436 - Dense0_loss: 4.8836 - Dense1_loss: 2.8095 - Dense2_loss: 1.7327 - Dense3_loss: 8.9723 - Dense0_acc: 0.6965 - Dense1_acc: 0.8244 - Dense2_acc: 0.8925 - Dense3_acc: 0.4423 - val_loss: 21.7753 - val_Dense0_loss: 4.4002 - val_Dense1_loss: 2.2931 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3051 - val_Dense0_acc: 0.7270 - val_Dense1_acc: 0.8575 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4220
Current time ....51.432
Epoch 4/10
 - 16s - loss: 23.7082 - Dense0_loss: 6.5901 - Dense1_loss: 2.7163 - Dense2_loss: 1.7336 - Dense3_loss: 9.4879 - Dense0_acc: 0.5909 - Dense1_acc: 0.8309 - Dense2_acc: 0.8924 - Dense3_acc: 0.4111 - val_loss: 23.1407 - val_Dense0_loss: 7.0758 - val_Dense1_loss: 2.2804 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.2426 - val_Dense0_acc: 0.5610 - val_Dense1_acc: 0.8580 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4255
Current time ....67.463
Epoch 5/10
 - 16s - loss: 23.5214 - Dense0_loss: 6.8352 - Dense1_loss: 2.6323 - Dense2_loss: 1.7357 - Dense3_loss: 9.2741 - Dense0_acc: 0.5755 - Dense1_acc: 0.8361 - Dense2_acc: 0.8922 - Dense3_acc: 0.4241 - val_loss: 21.6916 - val_Dense0_loss: 5.8264 - val_Dense1_loss: 1.9184 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.6071 - val_Dense0_acc: 0.6385 - val_Dense1_acc: 0.8805 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4660
Current time ....83.452
Epoch 6/10
 - 16s - loss: 22.6259 - Dense0_loss: 6.1829 - Dense1_loss: 2.8475 - Dense2_loss: 1.7327 - Dense3_loss: 8.6205 - Dense0_acc: 0.6161 - Dense1_acc: 0.8227 - Dense2_acc: 0.8925 - Dense3_acc: 0.4651 - val_loss: 22.3551 - val_Dense0_loss: 6.9308 - val_Dense1_loss: 1.8866 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.5700 - val_Dense1_acc: 0.8825 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....99.475
Epoch 7/10
 - 16s - loss: 21.3986 - Dense0_loss: 6.7615 - Dense1_loss: 2.1106 - Dense2_loss: 1.7327 - Dense3_loss: 8.6514 - Dense0_acc: 0.5805 - Dense1_acc: 0.8690 - Dense2_acc: 0.8925 - Dense3_acc: 0.4633 - val_loss: 21.3077 - val_Dense0_loss: 6.9308 - val_Dense1_loss: 2.1679 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.5700 - val_Dense1_acc: 0.8655 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....115.493
Epoch 8/10
 - 16s - loss: 22.8556 - Dense0_loss: 6.3376 - Dense1_loss: 3.4913 - Dense2_loss: 1.7327 - Dense3_loss: 8.6514 - Dense0_acc: 0.6063 - Dense1_acc: 0.7832 - Dense2_acc: 0.8925 - Dense3_acc: 0.4633 - val_loss: 27.9978 - val_Dense0_loss: 6.2899 - val_Dense1_loss: 6.5520 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.6095 - val_Dense1_acc: 0.5935 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....131.504
Epoch 9/10
 - 16s - loss: 26.1912 - Dense0_loss: 6.2782 - Dense1_loss: 6.8885 - Dense2_loss: 1.7327 - Dense3_loss: 8.6514 - Dense0_acc: 0.6104 - Dense1_acc: 0.5726 - Dense2_acc: 0.8925 - Dense3_acc: 0.4633 - val_loss: 24.6233 - val_Dense0_loss: 5.0747 - val_Dense1_loss: 6.5278 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.6845 - val_Dense1_acc: 0.5950 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....147.542
Epoch 10/10
 - 16s - loss: 25.1058 - Dense0_loss: 5.9093 - Dense1_loss: 6.9207 - Dense2_loss: 1.7327 - Dense3_loss: 8.6514 - Dense0_acc: 0.6334 - Dense1_acc: 0.5706 - Dense2_acc: 0.8925 - Dense3_acc: 0.4633 - val_loss: 24.9171 - val_Dense0_loss: 6.1630 - val_Dense1_loss: 6.5681 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.6175 - val_Dense1_acc: 0.5925 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....163.537
Return:  <keras.callbacks.History object at 0x7fa00be56dd8>
172836
start time: 04:16:53
