Importing candle utils for keras
Configuration file:  /home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/p3b3_default_model.txt
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'filter_sets': 3,
 'filter_sizes': 3,
 'learning_rate': 0.01,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'train_data': 'P3B3_data.tar.gz',
 'w_l2': 0.01,
 'wv_len': 300}
Params:
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'datatype': <class 'numpy.float32'>,
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'experiment_id': 'EXP000',
 'filter_sets': 3,
 'filter_sizes': 3,
 'gpus': [],
 'learning_rate': 0.01,
 'logfile': None,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'output_dir': '/home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/Output/EXP000/RUN000',
 'rng_seed': 7102,
 'run_id': 'RUN000',
 'shuffle': False,
 'timeout': -1,
 'train_bool': True,
 'train_data': 'P3B3_data.tar.gz',
 'verbose': None,
 'w_l2': 0.01,
 'wv_len': 300}
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input (InputLayer)              (None, 1500)         0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 1500, 300)    1396200     Input[0][0]                      
__________________________________________________________________________________________________
0_thfilter (Conv1D)             (None, 1500, 100)    90100       embedding[0][0]                  
__________________________________________________________________________________________________
1_thfilter (Conv1D)             (None, 1500, 100)    120100      embedding[0][0]                  
__________________________________________________________________________________________________
2_thfilter (Conv1D)             (None, 1500, 100)    150100      embedding[0][0]                  
__________________________________________________________________________________________________
global_max_pooling1d_1 (GlobalM (None, 100)          0           0_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_2 (GlobalM (None, 100)          0           1_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_3 (GlobalM (None, 100)          0           2_thfilter[0][0]                 
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 300)          0           global_max_pooling1d_1[0][0]     
                                                                 global_max_pooling1d_2[0][0]     
                                                                 global_max_pooling1d_3[0][0]     
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 300)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
Dense0 (Dense)                  (None, 6)            1806        dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense1 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense2 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense3 (Dense)                  (None, 3)            903         dropout_1[0][0]                  
==================================================================================================
Total params: 1,760,413
Trainable params: 1,760,413
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 8000 samples, validate on 2000 samples
Epoch 1/10
 - 17s - loss: 17.4633 - Dense0_loss: 2.9250 - Dense1_loss: 1.3968 - Dense2_loss: 1.1375 - Dense3_loss: 3.1564 - Dense0_acc: 0.7191 - Dense1_acc: 0.8421 - Dense2_acc: 0.8927 - Dense3_acc: 0.6358 - val_loss: 24.7023 - val_Dense0_loss: 3.9088 - val_Dense1_loss: 3.4243 - val_Dense2_loss: 1.9288 - val_Dense3_loss: 5.0618 - val_Dense0_acc: 0.7540 - val_Dense1_acc: 0.7815 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.6750
Current time ....17.435
Epoch 2/10
 - 14s - loss: 23.2311 - Dense0_loss: 4.6184 - Dense1_loss: 2.3243 - Dense2_loss: 1.7251 - Dense3_loss: 7.2292 - Dense0_acc: 0.7084 - Dense1_acc: 0.8496 - Dense2_acc: 0.8920 - Dense3_acc: 0.5440 - val_loss: 24.6571 - val_Dense0_loss: 6.0290 - val_Dense1_loss: 1.7993 - val_Dense2_loss: 1.9223 - val_Dense3_loss: 9.1874 - val_Dense0_acc: 0.6245 - val_Dense1_acc: 0.8880 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4260
Current time ....31.433
Epoch 3/10
 - 14s - loss: 21.6090 - Dense0_loss: 4.5153 - Dense1_loss: 2.4105 - Dense2_loss: 1.7290 - Dense3_loss: 8.4658 - Dense0_acc: 0.7175 - Dense1_acc: 0.8482 - Dense2_acc: 0.8924 - Dense3_acc: 0.4726 - val_loss: 22.3736 - val_Dense0_loss: 4.3680 - val_Dense1_loss: 2.5044 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.5000 - val_Dense0_acc: 0.7290 - val_Dense1_acc: 0.8445 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4720
Current time ....45.472
Epoch 4/10
 - 14s - loss: 23.0971 - Dense0_loss: 4.9984 - Dense1_loss: 3.6038 - Dense2_loss: 1.7337 - Dense3_loss: 7.9121 - Dense0_acc: 0.6895 - Dense1_acc: 0.7755 - Dense2_acc: 0.8924 - Dense3_acc: 0.5084 - val_loss: 23.5839 - val_Dense0_loss: 5.4400 - val_Dense1_loss: 3.3770 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 7.7789 - val_Dense0_acc: 0.6620 - val_Dense1_acc: 0.7905 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.5165
Current time ....59.538
Epoch 5/10
 - 14s - loss: 21.9915 - Dense0_loss: 5.1569 - Dense1_loss: 2.5867 - Dense2_loss: 1.7327 - Dense3_loss: 8.3408 - Dense0_acc: 0.6800 - Dense1_acc: 0.8391 - Dense2_acc: 0.8925 - Dense3_acc: 0.4824 - val_loss: 20.1213 - val_Dense0_loss: 4.3519 - val_Dense1_loss: 1.8770 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.7300 - val_Dense1_acc: 0.8830 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....73.570
Epoch 6/10
 - 14s - loss: 21.4115 - Dense0_loss: 4.5372 - Dense1_loss: 4.3930 - Dense2_loss: 1.7327 - Dense3_loss: 8.6453 - Dense0_acc: 0.7185 - Dense1_acc: 0.7274 - Dense2_acc: 0.8925 - Dense3_acc: 0.4636 - val_loss: 23.1676 - val_Dense0_loss: 4.3438 - val_Dense1_loss: 6.5359 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.7305 - val_Dense1_acc: 0.5945 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....87.637
Epoch 7/10
 - 14s - loss: 23.4049 - Dense0_loss: 4.7378 - Dense1_loss: 6.8784 - Dense2_loss: 1.7327 - Dense3_loss: 8.6413 - Dense0_acc: 0.7060 - Dense1_acc: 0.5733 - Dense2_acc: 0.8925 - Dense3_acc: 0.4639 - val_loss: 22.6591 - val_Dense0_loss: 4.3438 - val_Dense1_loss: 6.5525 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.7305 - val_Dense1_acc: 0.5930 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....101.675
Epoch 8/10
 - 14s - loss: 23.0885 - Dense0_loss: 6.4985 - Dense1_loss: 4.3940 - Dense2_loss: 1.7327 - Dense3_loss: 8.6600 - Dense0_acc: 0.5966 - Dense1_acc: 0.7271 - Dense2_acc: 0.8925 - Dense3_acc: 0.4626 - val_loss: 21.3277 - val_Dense0_loss: 6.8464 - val_Dense1_loss: 2.4044 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.5750 - val_Dense1_acc: 0.8505 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....115.746
Epoch 9/10
 - 14s - loss: 25.0596 - Dense0_loss: 7.2013 - Dense1_loss: 5.0708 - Dense2_loss: 1.7327 - Dense3_loss: 8.6534 - Dense0_acc: 0.5530 - Dense1_acc: 0.6853 - Dense2_acc: 0.8925 - Dense3_acc: 0.4631 - val_loss: 25.2464 - val_Dense0_loss: 7.1161 - val_Dense1_loss: 4.5249 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.5585 - val_Dense1_acc: 0.7190 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....129.817
Epoch 10/10
 - 14s - loss: 22.3749 - Dense0_loss: 7.2813 - Dense1_loss: 2.5624 - Dense2_loss: 1.7327 - Dense3_loss: 8.6534 - Dense0_acc: 0.5483 - Dense1_acc: 0.8409 - Dense2_acc: 0.8925 - Dense3_acc: 0.4631 - val_loss: 22.2238 - val_Dense0_loss: 7.1242 - val_Dense1_loss: 2.3453 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.5580 - val_Dense1_acc: 0.8540 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....143.890
Return:  <keras.callbacks.History object at 0x7f79cf817dd8>
152930
start time: 23:54:17
