Importing candle utils for keras
Configuration file:  /home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/p3b3_default_model.txt
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'filter_sets': 3,
 'filter_sizes': 3,
 'learning_rate': 0.01,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'train_data': 'P3B3_data.tar.gz',
 'w_l2': 0.01,
 'wv_len': 300}
Params:
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'datatype': <class 'numpy.float32'>,
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'experiment_id': 'EXP000',
 'filter_sets': 3,
 'filter_sizes': 3,
 'gpus': [],
 'learning_rate': 0.01,
 'logfile': None,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'output_dir': '/home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/Output/EXP000/RUN000',
 'rng_seed': 7102,
 'run_id': 'RUN000',
 'shuffle': False,
 'timeout': -1,
 'train_bool': True,
 'train_data': 'P3B3_data.tar.gz',
 'verbose': None,
 'w_l2': 0.01,
 'wv_len': 300}
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input (InputLayer)              (None, 1500)         0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 1500, 300)    1396200     Input[0][0]                      
__________________________________________________________________________________________________
0_thfilter (Conv1D)             (None, 1500, 100)    90100       embedding[0][0]                  
__________________________________________________________________________________________________
1_thfilter (Conv1D)             (None, 1500, 100)    120100      embedding[0][0]                  
__________________________________________________________________________________________________
2_thfilter (Conv1D)             (None, 1500, 100)    150100      embedding[0][0]                  
__________________________________________________________________________________________________
global_max_pooling1d_1 (GlobalM (None, 100)          0           0_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_2 (GlobalM (None, 100)          0           1_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_3 (GlobalM (None, 100)          0           2_thfilter[0][0]                 
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 300)          0           global_max_pooling1d_1[0][0]     
                                                                 global_max_pooling1d_2[0][0]     
                                                                 global_max_pooling1d_3[0][0]     
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 300)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
Dense0 (Dense)                  (None, 6)            1806        dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense1 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense2 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense3 (Dense)                  (None, 3)            903         dropout_1[0][0]                  
==================================================================================================
Total params: 1,760,413
Trainable params: 1,760,413
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 8000 samples, validate on 2000 samples
Epoch 1/10
 - 22s - loss: 17.2828 - Dense0_loss: 2.6483 - Dense1_loss: 1.4294 - Dense2_loss: 1.0799 - Dense3_loss: 3.7006 - Dense0_acc: 0.7391 - Dense1_acc: 0.8362 - Dense2_acc: 0.8942 - Dense3_acc: 0.6093 - val_loss: 22.6404 - val_Dense0_loss: 3.8344 - val_Dense1_loss: 2.2061 - val_Dense2_loss: 1.9231 - val_Dense3_loss: 6.0472 - val_Dense0_acc: 0.7560 - val_Dense1_acc: 0.8575 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.6140
Current time ....21.792
Epoch 2/10
 - 18s - loss: 23.5544 - Dense0_loss: 4.3762 - Dense1_loss: 3.0103 - Dense2_loss: 1.7299 - Dense3_loss: 7.4512 - Dense0_acc: 0.7250 - Dense1_acc: 0.8092 - Dense2_acc: 0.8920 - Dense3_acc: 0.5331 - val_loss: 22.4042 - val_Dense0_loss: 4.3115 - val_Dense1_loss: 2.7964 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 7.4305 - val_Dense0_acc: 0.7325 - val_Dense1_acc: 0.8245 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.5390
Current time ....40.262
Epoch 3/10
 - 18s - loss: 22.2761 - Dense0_loss: 4.6465 - Dense1_loss: 2.7390 - Dense2_loss: 1.7329 - Dense3_loss: 7.9732 - Dense0_acc: 0.7111 - Dense1_acc: 0.8291 - Dense2_acc: 0.8924 - Dense3_acc: 0.5048 - val_loss: 20.6023 - val_Dense0_loss: 4.4343 - val_Dense1_loss: 1.7783 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 7.4466 - val_Dense0_acc: 0.7245 - val_Dense1_acc: 0.8880 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.5380
Current time ....58.727
Epoch 4/10
 - 18s - loss: 21.8955 - Dense0_loss: 4.6986 - Dense1_loss: 2.4141 - Dense2_loss: 1.7327 - Dense3_loss: 8.1435 - Dense0_acc: 0.7079 - Dense1_acc: 0.8496 - Dense2_acc: 0.8925 - Dense3_acc: 0.4941 - val_loss: 21.4517 - val_Dense0_loss: 4.0456 - val_Dense1_loss: 2.1912 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9052 - val_Dense0_acc: 0.7490 - val_Dense1_acc: 0.8630 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4475
Current time ....77.185
Epoch 5/10
 - 18s - loss: 21.2600 - Dense0_loss: 4.8437 - Dense1_loss: 2.4569 - Dense2_loss: 1.7327 - Dense3_loss: 8.4559 - Dense0_acc: 0.6994 - Dense1_acc: 0.8470 - Dense2_acc: 0.8925 - Dense3_acc: 0.4751 - val_loss: 25.8528 - val_Dense0_loss: 8.1339 - val_Dense1_loss: 3.2791 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.8972 - val_Dense0_acc: 0.4940 - val_Dense1_acc: 0.7965 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4480
Current time ....95.630
Epoch 6/10
 - 18s - loss: 21.3035 - Dense0_loss: 5.4627 - Dense1_loss: 2.4981 - Dense2_loss: 1.7327 - Dense3_loss: 8.6469 - Dense0_acc: 0.6609 - Dense1_acc: 0.8449 - Dense2_acc: 0.8925 - Dense3_acc: 0.4633 - val_loss: 21.5589 - val_Dense0_loss: 6.3165 - val_Dense1_loss: 2.1686 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.6080 - val_Dense1_acc: 0.8650 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....114.025
Epoch 7/10
 - 18s - loss: 22.1111 - Dense0_loss: 5.5655 - Dense1_loss: 3.7451 - Dense2_loss: 1.7367 - Dense3_loss: 8.6514 - Dense0_acc: 0.6545 - Dense1_acc: 0.7674 - Dense2_acc: 0.8922 - Dense3_acc: 0.4633 - val_loss: 24.4635 - val_Dense0_loss: 4.3966 - val_Dense1_loss: 6.5520 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.7260 - val_Dense1_acc: 0.5935 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....132.481
Epoch 8/10
 - 18s - loss: 22.9080 - Dense0_loss: 4.7478 - Dense1_loss: 5.5579 - Dense2_loss: 1.7387 - Dense3_loss: 8.4814 - Dense0_acc: 0.7054 - Dense1_acc: 0.6550 - Dense2_acc: 0.8921 - Dense3_acc: 0.4735 - val_loss: 21.9680 - val_Dense0_loss: 5.6736 - val_Dense1_loss: 2.0538 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.7534 - val_Dense0_acc: 0.6480 - val_Dense1_acc: 0.8725 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4565
Current time ....150.958
Epoch 9/10
 - 18s - loss: 21.6934 - Dense0_loss: 4.7463 - Dense1_loss: 4.3207 - Dense2_loss: 1.7350 - Dense3_loss: 7.7599 - Dense0_acc: 0.7054 - Dense1_acc: 0.7316 - Dense2_acc: 0.8922 - Dense3_acc: 0.5184 - val_loss: 23.2224 - val_Dense0_loss: 4.3438 - val_Dense1_loss: 6.5037 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 7.6722 - val_Dense0_acc: 0.7305 - val_Dense1_acc: 0.5965 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.5240
Current time ....169.416
Epoch 10/10
 - 18s - loss: 21.0643 - Dense0_loss: 4.4184 - Dense1_loss: 4.8787 - Dense2_loss: 1.7327 - Dense3_loss: 7.7548 - Dense0_acc: 0.7259 - Dense1_acc: 0.6971 - Dense2_acc: 0.8925 - Dense3_acc: 0.5189 - val_loss: 19.0021 - val_Dense0_loss: 4.3438 - val_Dense1_loss: 3.2021 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 7.7125 - val_Dense0_acc: 0.7305 - val_Dense1_acc: 0.8005 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.5215
Current time ....187.891
Return:  <keras.callbacks.History object at 0x7f841b8ca0f0>
196516
start time: 04:38:39
