Importing candle utils for keras
Configuration file:  /home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/p3b3_default_model.txt
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'filter_sets': 3,
 'filter_sizes': 3,
 'learning_rate': 0.01,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'train_data': 'P3B3_data.tar.gz',
 'w_l2': 0.01,
 'wv_len': 300}
Params:
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'datatype': <class 'numpy.float32'>,
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'experiment_id': 'EXP000',
 'filter_sets': 3,
 'filter_sizes': 3,
 'gpus': [],
 'learning_rate': 0.01,
 'logfile': None,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'output_dir': '/home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/Output/EXP000/RUN000',
 'rng_seed': 7102,
 'run_id': 'RUN000',
 'shuffle': False,
 'timeout': -1,
 'train_bool': True,
 'train_data': 'P3B3_data.tar.gz',
 'verbose': None,
 'w_l2': 0.01,
 'wv_len': 300}
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input (InputLayer)              (None, 1500)         0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 1500, 300)    1396200     Input[0][0]                      
__________________________________________________________________________________________________
0_thfilter (Conv1D)             (None, 1500, 100)    90100       embedding[0][0]                  
__________________________________________________________________________________________________
1_thfilter (Conv1D)             (None, 1500, 100)    120100      embedding[0][0]                  
__________________________________________________________________________________________________
2_thfilter (Conv1D)             (None, 1500, 100)    150100      embedding[0][0]                  
__________________________________________________________________________________________________
global_max_pooling1d_1 (GlobalM (None, 100)          0           0_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_2 (GlobalM (None, 100)          0           1_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_3 (GlobalM (None, 100)          0           2_thfilter[0][0]                 
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 300)          0           global_max_pooling1d_1[0][0]     
                                                                 global_max_pooling1d_2[0][0]     
                                                                 global_max_pooling1d_3[0][0]     
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 300)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
Dense0 (Dense)                  (None, 6)            1806        dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense1 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense2 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense3 (Dense)                  (None, 3)            903         dropout_1[0][0]                  
==================================================================================================
Total params: 1,760,413
Trainable params: 1,760,413
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 8000 samples, validate on 2000 samples
Epoch 1/10
 - 19s - loss: 17.1032 - Dense0_loss: 2.6651 - Dense1_loss: 1.4117 - Dense2_loss: 1.1167 - Dense3_loss: 3.4131 - Dense0_acc: 0.7345 - Dense1_acc: 0.8422 - Dense2_acc: 0.8931 - Dense3_acc: 0.6246 - val_loss: 25.9135 - val_Dense0_loss: 4.6966 - val_Dense1_loss: 1.6903 - val_Dense2_loss: 1.9182 - val_Dense3_loss: 7.6360 - val_Dense0_acc: 0.7025 - val_Dense1_acc: 0.8890 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.5145
Current time ....18.617
Epoch 2/10
 - 15s - loss: 22.5440 - Dense0_loss: 4.2164 - Dense1_loss: 2.2652 - Dense2_loss: 1.7407 - Dense3_loss: 7.4438 - Dense0_acc: 0.7350 - Dense1_acc: 0.8549 - Dense2_acc: 0.8907 - Dense3_acc: 0.5328 - val_loss: 21.8292 - val_Dense0_loss: 4.0859 - val_Dense1_loss: 1.5393 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.7183 - val_Dense0_acc: 0.7460 - val_Dense1_acc: 0.9045 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4580
Current time ....33.792
Epoch 3/10
 - 15s - loss: 22.5592 - Dense0_loss: 5.0896 - Dense1_loss: 2.6506 - Dense2_loss: 1.7353 - Dense3_loss: 8.1503 - Dense0_acc: 0.6833 - Dense1_acc: 0.8349 - Dense2_acc: 0.8921 - Dense3_acc: 0.4931 - val_loss: 25.3115 - val_Dense0_loss: 5.8436 - val_Dense1_loss: 4.2913 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.4217 - val_Dense0_acc: 0.6370 - val_Dense1_acc: 0.7330 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4775
Current time ....48.981
Epoch 4/10
 - 15s - loss: 23.2838 - Dense0_loss: 5.2373 - Dense1_loss: 3.4078 - Dense2_loss: 1.7327 - Dense3_loss: 8.7200 - Dense0_acc: 0.6750 - Dense1_acc: 0.7881 - Dense2_acc: 0.8925 - Dense3_acc: 0.4586 - val_loss: 19.6499 - val_Dense0_loss: 4.4667 - val_Dense1_loss: 2.2526 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 7.6519 - val_Dense0_acc: 0.7225 - val_Dense1_acc: 0.8600 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.5250
Current time ....64.166
Epoch 5/10
 - 15s - loss: 23.2934 - Dense0_loss: 5.0188 - Dense1_loss: 3.2266 - Dense2_loss: 1.7327 - Dense3_loss: 8.6154 - Dense0_acc: 0.6878 - Dense1_acc: 0.7990 - Dense2_acc: 0.8925 - Dense3_acc: 0.4653 - val_loss: 21.9261 - val_Dense0_loss: 4.2525 - val_Dense1_loss: 1.6521 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.7355 - val_Dense1_acc: 0.8975 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....79.340
Epoch 6/10
 - 15s - loss: 22.9213 - Dense0_loss: 4.4760 - Dense1_loss: 4.0721 - Dense2_loss: 1.7327 - Dense3_loss: 8.6267 - Dense0_acc: 0.7223 - Dense1_acc: 0.7472 - Dense2_acc: 0.8925 - Dense3_acc: 0.4646 - val_loss: 24.5434 - val_Dense0_loss: 4.3448 - val_Dense1_loss: 5.6873 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.7300 - val_Dense1_acc: 0.6465 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....94.544
Epoch 7/10
 - 15s - loss: 21.4413 - Dense0_loss: 4.6481 - Dense1_loss: 2.8132 - Dense2_loss: 1.7327 - Dense3_loss: 8.6609 - Dense0_acc: 0.7116 - Dense1_acc: 0.8249 - Dense2_acc: 0.8925 - Dense3_acc: 0.4625 - val_loss: 24.4018 - val_Dense0_loss: 4.2936 - val_Dense1_loss: 5.0878 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.7335 - val_Dense1_acc: 0.6840 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....109.726
Epoch 8/10
 - 15s - loss: 23.8650 - Dense0_loss: 5.1663 - Dense1_loss: 4.4088 - Dense2_loss: 1.7327 - Dense3_loss: 8.3864 - Dense0_acc: 0.6794 - Dense1_acc: 0.7261 - Dense2_acc: 0.8925 - Dense3_acc: 0.4794 - val_loss: 25.3721 - val_Dense0_loss: 8.8634 - val_Dense1_loss: 1.8455 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.2363 - val_Dense0_acc: 0.4495 - val_Dense1_acc: 0.8855 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4890
Current time ....124.896
Epoch 9/10
 - 15s - loss: 23.2335 - Dense0_loss: 6.6779 - Dense1_loss: 2.0747 - Dense2_loss: 1.7327 - Dense3_loss: 8.4383 - Dense0_acc: 0.5855 - Dense1_acc: 0.8711 - Dense2_acc: 0.8925 - Dense3_acc: 0.4761 - val_loss: 19.8264 - val_Dense0_loss: 4.1790 - val_Dense1_loss: 2.0100 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.4298 - val_Dense0_acc: 0.7405 - val_Dense1_acc: 0.8750 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4770
Current time ....140.070
Epoch 10/10
 - 15s - loss: 20.2958 - Dense0_loss: 4.3447 - Dense1_loss: 2.6144 - Dense2_loss: 1.7327 - Dense3_loss: 8.4671 - Dense0_acc: 0.7304 - Dense1_acc: 0.8376 - Dense2_acc: 0.8925 - Dense3_acc: 0.4746 - val_loss: 19.4073 - val_Dense0_loss: 4.0456 - val_Dense1_loss: 1.9008 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 7.5110 - val_Dense0_acc: 0.7490 - val_Dense1_acc: 0.8815 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.5340
Current time ....155.245
Return:  <keras.callbacks.History object at 0x7f5bfd8f3dd8>
164269
start time: 00:26:32
