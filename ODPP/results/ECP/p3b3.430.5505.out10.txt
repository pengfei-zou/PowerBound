Importing candle utils for keras
Configuration file:  /home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/p3b3_default_model.txt
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'filter_sets': 3,
 'filter_sizes': 3,
 'learning_rate': 0.01,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'train_data': 'P3B3_data.tar.gz',
 'w_l2': 0.01,
 'wv_len': 300}
Params:
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'datatype': <class 'numpy.float32'>,
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'experiment_id': 'EXP000',
 'filter_sets': 3,
 'filter_sizes': 3,
 'gpus': [],
 'learning_rate': 0.01,
 'logfile': None,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'output_dir': '/home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/Output/EXP000/RUN000',
 'rng_seed': 7102,
 'run_id': 'RUN000',
 'shuffle': False,
 'timeout': -1,
 'train_bool': True,
 'train_data': 'P3B3_data.tar.gz',
 'verbose': None,
 'w_l2': 0.01,
 'wv_len': 300}
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input (InputLayer)              (None, 1500)         0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 1500, 300)    1396200     Input[0][0]                      
__________________________________________________________________________________________________
0_thfilter (Conv1D)             (None, 1500, 100)    90100       embedding[0][0]                  
__________________________________________________________________________________________________
1_thfilter (Conv1D)             (None, 1500, 100)    120100      embedding[0][0]                  
__________________________________________________________________________________________________
2_thfilter (Conv1D)             (None, 1500, 100)    150100      embedding[0][0]                  
__________________________________________________________________________________________________
global_max_pooling1d_1 (GlobalM (None, 100)          0           0_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_2 (GlobalM (None, 100)          0           1_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_3 (GlobalM (None, 100)          0           2_thfilter[0][0]                 
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 300)          0           global_max_pooling1d_1[0][0]     
                                                                 global_max_pooling1d_2[0][0]     
                                                                 global_max_pooling1d_3[0][0]     
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 300)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
Dense0 (Dense)                  (None, 6)            1806        dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense1 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense2 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense3 (Dense)                  (None, 3)            903         dropout_1[0][0]                  
==================================================================================================
Total params: 1,760,413
Trainable params: 1,760,413
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 8000 samples, validate on 2000 samples
Epoch 1/10
 - 45s - loss: 18.5221 - Dense0_loss: 2.6393 - Dense1_loss: 2.0287 - Dense2_loss: 1.0779 - Dense3_loss: 3.4685 - Dense0_acc: 0.7390 - Dense1_acc: 0.7979 - Dense2_acc: 0.8922 - Dense3_acc: 0.6185 - val_loss: 33.9785 - val_Dense0_loss: 3.9762 - val_Dense1_loss: 9.1782 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.7185 - val_Dense0_acc: 0.7490 - val_Dense1_acc: 0.4280 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4505
Current time ....45.253
Epoch 2/10
 - 42s - loss: 24.9120 - Dense0_loss: 4.7757 - Dense1_loss: 4.6306 - Dense2_loss: 1.7365 - Dense3_loss: 8.6400 - Dense0_acc: 0.7018 - Dense1_acc: 0.7105 - Dense2_acc: 0.8920 - Dense3_acc: 0.4635 - val_loss: 21.9742 - val_Dense0_loss: 5.5957 - val_Dense1_loss: 2.2613 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9187 - val_Dense0_acc: 0.6515 - val_Dense1_acc: 0.8575 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4465
Current time ....87.196
Epoch 3/10
 - 42s - loss: 21.8969 - Dense0_loss: 5.2483 - Dense1_loss: 3.3651 - Dense2_loss: 1.7327 - Dense3_loss: 8.6438 - Dense0_acc: 0.6733 - Dense1_acc: 0.7902 - Dense2_acc: 0.8925 - Dense3_acc: 0.4631 - val_loss: 22.3170 - val_Dense0_loss: 6.8989 - val_Dense1_loss: 1.9263 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.5715 - val_Dense1_acc: 0.8805 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....129.123
Epoch 4/10
 - 42s - loss: 23.2148 - Dense0_loss: 6.7785 - Dense1_loss: 3.8775 - Dense2_loss: 1.7327 - Dense3_loss: 8.6532 - Dense0_acc: 0.5789 - Dense1_acc: 0.7592 - Dense2_acc: 0.8925 - Dense3_acc: 0.4630 - val_loss: 22.5917 - val_Dense0_loss: 6.8744 - val_Dense1_loss: 2.4902 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.5735 - val_Dense1_acc: 0.8455 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....171.106
Epoch 5/10
 - 42s - loss: 19.2211 - Dense0_loss: 4.5136 - Dense1_loss: 2.1854 - Dense2_loss: 1.7327 - Dense3_loss: 8.6580 - Dense0_acc: 0.7196 - Dense1_acc: 0.8639 - Dense2_acc: 0.8925 - Dense3_acc: 0.4628 - val_loss: 19.3061 - val_Dense0_loss: 4.4083 - val_Dense1_loss: 1.6602 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.7265 - val_Dense1_acc: 0.8970 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....213.094
Epoch 6/10
 - 42s - loss: 19.6599 - Dense0_loss: 5.0405 - Dense1_loss: 2.0044 - Dense2_loss: 1.7327 - Dense3_loss: 8.6514 - Dense0_acc: 0.6870 - Dense1_acc: 0.8755 - Dense2_acc: 0.8925 - Dense3_acc: 0.4633 - val_loss: 19.0572 - val_Dense0_loss: 4.1182 - val_Dense1_loss: 1.9583 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.7445 - val_Dense1_acc: 0.8785 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....255.083
Epoch 7/10
 - 42s - loss: 21.0439 - Dense0_loss: 6.1462 - Dense1_loss: 2.0310 - Dense2_loss: 1.7327 - Dense3_loss: 8.6514 - Dense0_acc: 0.6184 - Dense1_acc: 0.8739 - Dense2_acc: 0.8925 - Dense3_acc: 0.4633 - val_loss: 18.5245 - val_Dense0_loss: 4.1826 - val_Dense1_loss: 1.8133 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.7405 - val_Dense1_acc: 0.8875 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....297.087
Epoch 8/10
 - 42s - loss: 19.2933 - Dense0_loss: 5.4632 - Dense1_loss: 1.9126 - Dense2_loss: 1.7327 - Dense3_loss: 8.6514 - Dense0_acc: 0.6609 - Dense1_acc: 0.8812 - Dense2_acc: 0.8925 - Dense3_acc: 0.4633 - val_loss: 18.9055 - val_Dense0_loss: 4.9155 - val_Dense1_loss: 1.8224 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.6950 - val_Dense1_acc: 0.8865 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....339.103
Epoch 9/10
 - 42s - loss: 21.0202 - Dense0_loss: 5.5257 - Dense1_loss: 3.0981 - Dense2_loss: 1.7327 - Dense3_loss: 8.6528 - Dense0_acc: 0.6570 - Dense1_acc: 0.8075 - Dense2_acc: 0.8925 - Dense3_acc: 0.4631 - val_loss: 24.0060 - val_Dense0_loss: 4.9243 - val_Dense1_loss: 6.0926 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.6945 - val_Dense1_acc: 0.6220 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....381.154
Epoch 10/10
 - 42s - loss: 25.5656 - Dense0_loss: 9.8822 - Dense1_loss: 3.2235 - Dense2_loss: 1.7327 - Dense3_loss: 8.6514 - Dense0_acc: 0.3868 - Dense1_acc: 0.7999 - Dense2_acc: 0.8925 - Dense3_acc: 0.4633 - val_loss: 26.8611 - val_Dense0_loss: 12.6205 - val_Dense1_loss: 1.7488 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.2170 - val_Dense1_acc: 0.8915 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....423.208
Return:  <keras.callbacks.History object at 0x7fc90905ddd8>
432151
start time: 05:51:06
