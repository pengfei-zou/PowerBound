Importing candle utils for keras
Configuration file:  /home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/p3b3_default_model.txt
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'filter_sets': 3,
 'filter_sizes': 3,
 'learning_rate': 0.01,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'train_data': 'P3B3_data.tar.gz',
 'w_l2': 0.01,
 'wv_len': 300}
Params:
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'datatype': <class 'numpy.float32'>,
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'experiment_id': 'EXP000',
 'filter_sets': 3,
 'filter_sizes': 3,
 'gpus': [],
 'learning_rate': 0.01,
 'logfile': None,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'output_dir': '/home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/Output/EXP000/RUN000',
 'rng_seed': 7102,
 'run_id': 'RUN000',
 'shuffle': False,
 'timeout': -1,
 'train_bool': True,
 'train_data': 'P3B3_data.tar.gz',
 'verbose': None,
 'w_l2': 0.01,
 'wv_len': 300}
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input (InputLayer)              (None, 1500)         0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 1500, 300)    1396200     Input[0][0]                      
__________________________________________________________________________________________________
0_thfilter (Conv1D)             (None, 1500, 100)    90100       embedding[0][0]                  
__________________________________________________________________________________________________
1_thfilter (Conv1D)             (None, 1500, 100)    120100      embedding[0][0]                  
__________________________________________________________________________________________________
2_thfilter (Conv1D)             (None, 1500, 100)    150100      embedding[0][0]                  
__________________________________________________________________________________________________
global_max_pooling1d_1 (GlobalM (None, 100)          0           0_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_2 (GlobalM (None, 100)          0           1_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_3 (GlobalM (None, 100)          0           2_thfilter[0][0]                 
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 300)          0           global_max_pooling1d_1[0][0]     
                                                                 global_max_pooling1d_2[0][0]     
                                                                 global_max_pooling1d_3[0][0]     
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 300)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
Dense0 (Dense)                  (None, 6)            1806        dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense1 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense2 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense3 (Dense)                  (None, 3)            903         dropout_1[0][0]                  
==================================================================================================
Total params: 1,760,413
Trainable params: 1,760,413
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 8000 samples, validate on 2000 samples
Epoch 1/10
 - 19s - loss: 18.0478 - Dense0_loss: 2.9974 - Dense1_loss: 1.5104 - Dense2_loss: 1.1146 - Dense3_loss: 3.8956 - Dense0_acc: 0.7228 - Dense1_acc: 0.8367 - Dense2_acc: 0.8954 - Dense3_acc: 0.6083 - val_loss: 25.8030 - val_Dense0_loss: 4.0140 - val_Dense1_loss: 1.2904 - val_Dense2_loss: 1.9283 - val_Dense3_loss: 9.2185 - val_Dense0_acc: 0.7495 - val_Dense1_acc: 0.9180 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4260
Current time ....19.255
Epoch 2/10
 - 16s - loss: 23.6885 - Dense0_loss: 4.6570 - Dense1_loss: 2.4451 - Dense2_loss: 1.7347 - Dense3_loss: 9.4579 - Dense0_acc: 0.7096 - Dense1_acc: 0.8456 - Dense2_acc: 0.8922 - Dense3_acc: 0.4121 - val_loss: 20.2909 - val_Dense0_loss: 4.0049 - val_Dense1_loss: 2.0835 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.2973 - val_Dense0_acc: 0.7510 - val_Dense1_acc: 0.8695 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4215
Current time ....35.185
Epoch 3/10
 - 16s - loss: 22.1858 - Dense0_loss: 4.6173 - Dense1_loss: 3.5310 - Dense2_loss: 1.7327 - Dense3_loss: 8.2567 - Dense0_acc: 0.7130 - Dense1_acc: 0.7799 - Dense2_acc: 0.8925 - Dense3_acc: 0.4856 - val_loss: 22.0166 - val_Dense0_loss: 4.5867 - val_Dense1_loss: 3.1845 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.8972 - val_Dense0_acc: 0.7150 - val_Dense1_acc: 0.8000 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4480
Current time ....51.010
Epoch 4/10
 - 16s - loss: 23.8125 - Dense0_loss: 6.2142 - Dense1_loss: 3.7622 - Dense2_loss: 1.7327 - Dense3_loss: 8.6517 - Dense0_acc: 0.6143 - Dense1_acc: 0.7657 - Dense2_acc: 0.8925 - Dense3_acc: 0.4631 - val_loss: 23.5630 - val_Dense0_loss: 7.0678 - val_Dense1_loss: 2.6032 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9636 - val_Dense0_acc: 0.5615 - val_Dense1_acc: 0.8365 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4430
Current time ....66.855
Epoch 5/10
 - 16s - loss: 23.7467 - Dense0_loss: 7.1907 - Dense1_loss: 3.7206 - Dense2_loss: 1.7327 - Dense3_loss: 8.6633 - Dense0_acc: 0.5539 - Dense1_acc: 0.7687 - Dense2_acc: 0.8925 - Dense3_acc: 0.4624 - val_loss: 22.1814 - val_Dense0_loss: 7.0678 - val_Dense1_loss: 2.2326 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.5615 - val_Dense1_acc: 0.8615 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....82.685
Epoch 6/10
 - 16s - loss: 21.8547 - Dense0_loss: 7.2390 - Dense1_loss: 2.2269 - Dense2_loss: 1.7327 - Dense3_loss: 8.6574 - Dense0_acc: 0.5509 - Dense1_acc: 0.8615 - Dense2_acc: 0.8925 - Dense3_acc: 0.4629 - val_loss: 21.4007 - val_Dense0_loss: 7.1000 - val_Dense1_loss: 1.7702 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.5595 - val_Dense1_acc: 0.8895 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....98.495
Epoch 7/10
 - 16s - loss: 21.2356 - Dense0_loss: 7.2834 - Dense1_loss: 2.1820 - Dense2_loss: 1.7327 - Dense3_loss: 8.6625 - Dense0_acc: 0.5481 - Dense1_acc: 0.8646 - Dense2_acc: 0.8925 - Dense3_acc: 0.4625 - val_loss: 21.2693 - val_Dense0_loss: 7.1081 - val_Dense1_loss: 2.3774 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.5590 - val_Dense1_acc: 0.8525 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....114.379
Epoch 8/10
 - 16s - loss: 21.0142 - Dense0_loss: 7.2914 - Dense1_loss: 2.6151 - Dense2_loss: 1.7327 - Dense3_loss: 8.6514 - Dense0_acc: 0.5476 - Dense1_acc: 0.8377 - Dense2_acc: 0.8925 - Dense3_acc: 0.4633 - val_loss: 24.8970 - val_Dense0_loss: 7.1161 - val_Dense1_loss: 5.9023 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.5585 - val_Dense1_acc: 0.6335 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....130.251
Epoch 9/10
 - 16s - loss: 25.6895 - Dense0_loss: 7.2934 - Dense1_loss: 6.7670 - Dense2_loss: 1.7327 - Dense3_loss: 8.6744 - Dense0_acc: 0.5475 - Dense1_acc: 0.5799 - Dense2_acc: 0.8925 - Dense3_acc: 0.4616 - val_loss: 25.4363 - val_Dense0_loss: 7.1161 - val_Dense1_loss: 6.5681 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.5585 - val_Dense1_acc: 0.5925 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....146.102
Epoch 10/10
 - 16s - loss: 25.2581 - Dense0_loss: 7.2874 - Dense1_loss: 6.9731 - Dense2_loss: 1.7327 - Dense3_loss: 8.6514 - Dense0_acc: 0.5479 - Dense1_acc: 0.5674 - Dense2_acc: 0.8925 - Dense3_acc: 0.4633 - val_loss: 24.9441 - val_Dense0_loss: 7.1161 - val_Dense1_loss: 6.5681 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.5585 - val_Dense1_acc: 0.5925 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....161.960
Return:  <keras.callbacks.History object at 0x7fe8b908fdd8>
170782
start time: 00:35:07
