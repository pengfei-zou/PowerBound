Importing candle utils for keras
Configuration file:  /home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/p3b3_default_model.txt
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'filter_sets': 3,
 'filter_sizes': 3,
 'learning_rate': 0.01,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'train_data': 'P3B3_data.tar.gz',
 'w_l2': 0.01,
 'wv_len': 300}
Params:
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'datatype': <class 'numpy.float32'>,
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'experiment_id': 'EXP000',
 'filter_sets': 3,
 'filter_sizes': 3,
 'gpus': [],
 'learning_rate': 0.01,
 'logfile': None,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'output_dir': '/home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/Output/EXP000/RUN000',
 'rng_seed': 7102,
 'run_id': 'RUN000',
 'shuffle': False,
 'timeout': -1,
 'train_bool': True,
 'train_data': 'P3B3_data.tar.gz',
 'verbose': None,
 'w_l2': 0.01,
 'wv_len': 300}
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input (InputLayer)              (None, 1500)         0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 1500, 300)    1396200     Input[0][0]                      
__________________________________________________________________________________________________
0_thfilter (Conv1D)             (None, 1500, 100)    90100       embedding[0][0]                  
__________________________________________________________________________________________________
1_thfilter (Conv1D)             (None, 1500, 100)    120100      embedding[0][0]                  
__________________________________________________________________________________________________
2_thfilter (Conv1D)             (None, 1500, 100)    150100      embedding[0][0]                  
__________________________________________________________________________________________________
global_max_pooling1d_1 (GlobalM (None, 100)          0           0_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_2 (GlobalM (None, 100)          0           1_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_3 (GlobalM (None, 100)          0           2_thfilter[0][0]                 
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 300)          0           global_max_pooling1d_1[0][0]     
                                                                 global_max_pooling1d_2[0][0]     
                                                                 global_max_pooling1d_3[0][0]     
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 300)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
Dense0 (Dense)                  (None, 6)            1806        dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense1 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense2 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense3 (Dense)                  (None, 3)            903         dropout_1[0][0]                  
==================================================================================================
Total params: 1,760,413
Trainable params: 1,760,413
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 8000 samples, validate on 2000 samples
Epoch 1/10
 - 18s - loss: 17.4012 - Dense0_loss: 2.5863 - Dense1_loss: 1.3421 - Dense2_loss: 1.1169 - Dense3_loss: 3.7820 - Dense0_acc: 0.7481 - Dense1_acc: 0.8416 - Dense2_acc: 0.8932 - Dense3_acc: 0.6148 - val_loss: 21.7887 - val_Dense0_loss: 3.9225 - val_Dense1_loss: 1.5412 - val_Dense2_loss: 1.9106 - val_Dense3_loss: 5.7822 - val_Dense0_acc: 0.7560 - val_Dense1_acc: 0.9015 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.6245
Current time ....17.864
Epoch 2/10
 - 15s - loss: 24.6866 - Dense0_loss: 4.4948 - Dense1_loss: 4.1659 - Dense2_loss: 1.7290 - Dense3_loss: 7.5411 - Dense0_acc: 0.7186 - Dense1_acc: 0.7385 - Dense2_acc: 0.8919 - Dense3_acc: 0.5290 - val_loss: 20.2911 - val_Dense0_loss: 3.9263 - val_Dense1_loss: 2.0681 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.7560 - val_Dense1_acc: 0.8695 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....32.479
Epoch 3/10
 - 15s - loss: 22.0899 - Dense0_loss: 5.1570 - Dense1_loss: 2.5673 - Dense2_loss: 1.7322 - Dense3_loss: 8.6534 - Dense0_acc: 0.6798 - Dense1_acc: 0.8392 - Dense2_acc: 0.8922 - Dense3_acc: 0.4631 - val_loss: 20.4459 - val_Dense0_loss: 4.0172 - val_Dense1_loss: 1.7730 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.7500 - val_Dense1_acc: 0.8900 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....47.112
Epoch 4/10
 - 15s - loss: 20.7890 - Dense0_loss: 5.1650 - Dense1_loss: 2.0534 - Dense2_loss: 1.7327 - Dense3_loss: 8.6612 - Dense0_acc: 0.6793 - Dense1_acc: 0.8721 - Dense2_acc: 0.8925 - Dense3_acc: 0.4626 - val_loss: 19.3012 - val_Dense0_loss: 3.9167 - val_Dense1_loss: 1.6843 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.7570 - val_Dense1_acc: 0.8955 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....61.706
Epoch 5/10
 - 15s - loss: 20.5780 - Dense0_loss: 4.3986 - Dense1_loss: 2.2785 - Dense2_loss: 1.7345 - Dense3_loss: 8.6514 - Dense0_acc: 0.7269 - Dense1_acc: 0.8580 - Dense2_acc: 0.8924 - Dense3_acc: 0.4633 - val_loss: 20.4150 - val_Dense0_loss: 3.9651 - val_Dense1_loss: 1.9022 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.7540 - val_Dense1_acc: 0.8820 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....76.357
Epoch 6/10
 - 15s - loss: 19.8442 - Dense0_loss: 4.1275 - Dense1_loss: 2.5273 - Dense2_loss: 1.7327 - Dense3_loss: 8.6514 - Dense0_acc: 0.7437 - Dense1_acc: 0.8429 - Dense2_acc: 0.8925 - Dense3_acc: 0.4633 - val_loss: 19.9849 - val_Dense0_loss: 3.9651 - val_Dense1_loss: 2.2419 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.7540 - val_Dense1_acc: 0.8605 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....90.989
Epoch 7/10
 - 15s - loss: 18.8976 - Dense0_loss: 4.2229 - Dense1_loss: 2.1744 - Dense2_loss: 1.7327 - Dense3_loss: 8.6514 - Dense0_acc: 0.7380 - Dense1_acc: 0.8650 - Dense2_acc: 0.8925 - Dense3_acc: 0.4633 - val_loss: 18.1707 - val_Dense0_loss: 4.0376 - val_Dense1_loss: 1.8688 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.7495 - val_Dense1_acc: 0.8835 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....105.553
Epoch 8/10
 - 15s - loss: 19.7385 - Dense0_loss: 4.4878 - Dense1_loss: 2.5223 - Dense2_loss: 1.7327 - Dense3_loss: 8.6514 - Dense0_acc: 0.7213 - Dense1_acc: 0.8434 - Dense2_acc: 0.8925 - Dense3_acc: 0.4633 - val_loss: 20.5656 - val_Dense0_loss: 4.8773 - val_Dense1_loss: 2.1952 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.6970 - val_Dense1_acc: 0.8635 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....120.141
Epoch 9/10
 - 15s - loss: 23.1316 - Dense0_loss: 6.9253 - Dense1_loss: 2.6458 - Dense2_loss: 1.7327 - Dense3_loss: 8.6474 - Dense0_acc: 0.5701 - Dense1_acc: 0.8356 - Dense2_acc: 0.8925 - Dense3_acc: 0.4635 - val_loss: 23.1931 - val_Dense0_loss: 5.5366 - val_Dense1_loss: 3.7236 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.6565 - val_Dense1_acc: 0.7685 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....134.710
Epoch 10/10
 - 15s - loss: 25.2847 - Dense0_loss: 8.2480 - Dense1_loss: 3.8853 - Dense2_loss: 1.7327 - Dense3_loss: 8.6514 - Dense0_acc: 0.4880 - Dense1_acc: 0.7589 - Dense2_acc: 0.8925 - Dense3_acc: 0.4633 - val_loss: 22.3322 - val_Dense0_loss: 6.1508 - val_Dense1_loss: 2.7585 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.6165 - val_Dense1_acc: 0.8285 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....149.276
Return:  <keras.callbacks.History object at 0x7f2aea1badd8>
157469
start time: 00:15:29
