Importing candle utils for keras
Configuration file:  /home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/p3b3_default_model.txt
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'filter_sets': 3,
 'filter_sizes': 3,
 'learning_rate': 0.01,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'train_data': 'P3B3_data.tar.gz',
 'w_l2': 0.01,
 'wv_len': 300}
Params:
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'datatype': <class 'numpy.float32'>,
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'experiment_id': 'EXP000',
 'filter_sets': 3,
 'filter_sizes': 3,
 'gpus': [],
 'learning_rate': 0.01,
 'logfile': None,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'output_dir': '/home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/Output/EXP000/RUN000',
 'rng_seed': 7102,
 'run_id': 'RUN000',
 'shuffle': False,
 'timeout': -1,
 'train_bool': True,
 'train_data': 'P3B3_data.tar.gz',
 'verbose': None,
 'w_l2': 0.01,
 'wv_len': 300}
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input (InputLayer)              (None, 1500)         0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 1500, 300)    1396200     Input[0][0]                      
__________________________________________________________________________________________________
0_thfilter (Conv1D)             (None, 1500, 100)    90100       embedding[0][0]                  
__________________________________________________________________________________________________
1_thfilter (Conv1D)             (None, 1500, 100)    120100      embedding[0][0]                  
__________________________________________________________________________________________________
2_thfilter (Conv1D)             (None, 1500, 100)    150100      embedding[0][0]                  
__________________________________________________________________________________________________
global_max_pooling1d_1 (GlobalM (None, 100)          0           0_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_2 (GlobalM (None, 100)          0           1_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_3 (GlobalM (None, 100)          0           2_thfilter[0][0]                 
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 300)          0           global_max_pooling1d_1[0][0]     
                                                                 global_max_pooling1d_2[0][0]     
                                                                 global_max_pooling1d_3[0][0]     
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 300)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
Dense0 (Dense)                  (None, 6)            1806        dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense1 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense2 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense3 (Dense)                  (None, 3)            903         dropout_1[0][0]                  
==================================================================================================
Total params: 1,760,413
Trainable params: 1,760,413
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 8000 samples, validate on 2000 samples
Epoch 1/10
 - 20s - loss: 17.1551 - Dense0_loss: 2.4327 - Dense1_loss: 1.4189 - Dense2_loss: 0.9955 - Dense3_loss: 3.7229 - Dense0_acc: 0.7477 - Dense1_acc: 0.8349 - Dense2_acc: 0.8987 - Dense3_acc: 0.6074 - val_loss: 26.5101 - val_Dense0_loss: 5.2997 - val_Dense1_loss: 1.3976 - val_Dense2_loss: 1.8178 - val_Dense3_loss: 8.5863 - val_Dense0_acc: 0.6640 - val_Dense1_acc: 0.9105 - val_Dense2_acc: 0.8840 - val_Dense3_acc: 0.4595
Current time ....19.548
Epoch 2/10
 - 16s - loss: 22.5266 - Dense0_loss: 4.6838 - Dense1_loss: 2.2000 - Dense2_loss: 1.6972 - Dense3_loss: 7.3059 - Dense0_acc: 0.7066 - Dense1_acc: 0.8585 - Dense2_acc: 0.8932 - Dense3_acc: 0.5410 - val_loss: 24.3146 - val_Dense0_loss: 6.9836 - val_Dense1_loss: 2.2704 - val_Dense2_loss: 1.9254 - val_Dense3_loss: 7.0110 - val_Dense0_acc: 0.5655 - val_Dense1_acc: 0.8575 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.5630
Current time ....35.881
Epoch 3/10
 - 17s - loss: 22.0135 - Dense0_loss: 4.8358 - Dense1_loss: 2.1353 - Dense2_loss: 1.7307 - Dense3_loss: 8.0573 - Dense0_acc: 0.6993 - Dense1_acc: 0.8666 - Dense2_acc: 0.8926 - Dense3_acc: 0.4989 - val_loss: 22.8569 - val_Dense0_loss: 4.2632 - val_Dense1_loss: 2.9501 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.2568 - val_Dense0_acc: 0.7355 - val_Dense1_acc: 0.8155 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4255
Current time ....52.410
Epoch 4/10
 - 17s - loss: 25.3918 - Dense0_loss: 4.3436 - Dense1_loss: 5.5417 - Dense2_loss: 1.7367 - Dense3_loss: 8.9574 - Dense0_acc: 0.7303 - Dense1_acc: 0.6555 - Dense2_acc: 0.8922 - Dense3_acc: 0.4439 - val_loss: 22.5248 - val_Dense0_loss: 4.4547 - val_Dense1_loss: 3.7669 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 7.8980 - val_Dense0_acc: 0.7230 - val_Dense1_acc: 0.7660 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.5095
Current time ....68.954
Epoch 5/10
 - 17s - loss: 26.1049 - Dense0_loss: 6.2674 - Dense1_loss: 5.8357 - Dense2_loss: 1.7357 - Dense3_loss: 8.2439 - Dense0_acc: 0.6111 - Dense1_acc: 0.6378 - Dense2_acc: 0.8922 - Dense3_acc: 0.4881 - val_loss: 27.4661 - val_Dense0_loss: 7.1161 - val_Dense1_loss: 6.5681 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.0431 - val_Dense0_acc: 0.5585 - val_Dense1_acc: 0.5925 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.5010
Current time ....85.472
Epoch 6/10
 - 17s - loss: 26.6117 - Dense0_loss: 7.1020 - Dense1_loss: 5.5771 - Dense2_loss: 1.7327 - Dense3_loss: 8.5110 - Dense0_acc: 0.5594 - Dense1_acc: 0.6536 - Dense2_acc: 0.8925 - Dense3_acc: 0.4718 - val_loss: 27.1263 - val_Dense0_loss: 7.1161 - val_Dense1_loss: 5.9153 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.5027 - val_Dense0_acc: 0.5585 - val_Dense1_acc: 0.6330 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4715
Current time ....102.037
Epoch 7/10
 - 17s - loss: 24.2465 - Dense0_loss: 7.2834 - Dense1_loss: 3.2291 - Dense2_loss: 1.7327 - Dense3_loss: 8.9507 - Dense0_acc: 0.5481 - Dense1_acc: 0.7995 - Dense2_acc: 0.8925 - Dense3_acc: 0.4446 - val_loss: 22.0141 - val_Dense0_loss: 7.1161 - val_Dense1_loss: 2.1679 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.4015 - val_Dense0_acc: 0.5585 - val_Dense1_acc: 0.8655 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4785
Current time ....118.569
Epoch 8/10
 - 17s - loss: 26.1558 - Dense0_loss: 7.2673 - Dense1_loss: 5.4862 - Dense2_loss: 1.7327 - Dense3_loss: 8.6371 - Dense0_acc: 0.5491 - Dense1_acc: 0.6594 - Dense2_acc: 0.8925 - Dense3_acc: 0.4640 - val_loss: 22.9442 - val_Dense0_loss: 7.1081 - val_Dense1_loss: 2.1840 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.5590 - val_Dense1_acc: 0.8645 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....135.093
Epoch 9/10
 - 17s - loss: 22.7694 - Dense0_loss: 7.2712 - Dense1_loss: 2.6098 - Dense2_loss: 1.7327 - Dense3_loss: 8.6534 - Dense0_acc: 0.5489 - Dense1_acc: 0.8379 - Dense2_acc: 0.8925 - Dense3_acc: 0.4631 - val_loss: 22.2519 - val_Dense0_loss: 7.1161 - val_Dense1_loss: 1.4667 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.5585 - val_Dense1_acc: 0.9090 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....151.649
Epoch 10/10
 - 16s - loss: 21.9090 - Dense0_loss: 7.2874 - Dense1_loss: 2.2082 - Dense2_loss: 1.7327 - Dense3_loss: 8.6514 - Dense0_acc: 0.5479 - Dense1_acc: 0.8630 - Dense2_acc: 0.8925 - Dense3_acc: 0.4633 - val_loss: 21.5525 - val_Dense0_loss: 7.1161 - val_Dense1_loss: 2.2565 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.5585 - val_Dense1_acc: 0.8600 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....168.071
Return:  <keras.callbacks.History object at 0x7f1a009d7a20>
177303
start time: 04:22:51
