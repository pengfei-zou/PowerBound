Importing candle utils for keras
Configuration file:  /home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/p3b3_default_model.txt
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'filter_sets': 3,
 'filter_sizes': 3,
 'learning_rate': 0.01,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'train_data': 'P3B3_data.tar.gz',
 'w_l2': 0.01,
 'wv_len': 300}
Params:
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'datatype': <class 'numpy.float32'>,
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'experiment_id': 'EXP000',
 'filter_sets': 3,
 'filter_sizes': 3,
 'gpus': [],
 'learning_rate': 0.01,
 'logfile': None,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'output_dir': '/home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/Output/EXP000/RUN000',
 'rng_seed': 7102,
 'run_id': 'RUN000',
 'shuffle': False,
 'timeout': -1,
 'train_bool': True,
 'train_data': 'P3B3_data.tar.gz',
 'verbose': None,
 'w_l2': 0.01,
 'wv_len': 300}
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input (InputLayer)              (None, 1500)         0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 1500, 300)    1396200     Input[0][0]                      
__________________________________________________________________________________________________
0_thfilter (Conv1D)             (None, 1500, 100)    90100       embedding[0][0]                  
__________________________________________________________________________________________________
1_thfilter (Conv1D)             (None, 1500, 100)    120100      embedding[0][0]                  
__________________________________________________________________________________________________
2_thfilter (Conv1D)             (None, 1500, 100)    150100      embedding[0][0]                  
__________________________________________________________________________________________________
global_max_pooling1d_1 (GlobalM (None, 100)          0           0_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_2 (GlobalM (None, 100)          0           1_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_3 (GlobalM (None, 100)          0           2_thfilter[0][0]                 
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 300)          0           global_max_pooling1d_1[0][0]     
                                                                 global_max_pooling1d_2[0][0]     
                                                                 global_max_pooling1d_3[0][0]     
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 300)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
Dense0 (Dense)                  (None, 6)            1806        dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense1 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense2 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense3 (Dense)                  (None, 3)            903         dropout_1[0][0]                  
==================================================================================================
Total params: 1,760,413
Trainable params: 1,760,413
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 8000 samples, validate on 2000 samples
Epoch 1/10
 - 26s - loss: 17.7659 - Dense0_loss: 2.7120 - Dense1_loss: 1.6929 - Dense2_loss: 1.1969 - Dense3_loss: 3.7637 - Dense0_acc: 0.7430 - Dense1_acc: 0.8320 - Dense2_acc: 0.8882 - Dense3_acc: 0.6111 - val_loss: 26.6006 - val_Dense0_loss: 3.4850 - val_Dense1_loss: 3.7951 - val_Dense2_loss: 1.9099 - val_Dense3_loss: 8.1265 - val_Dense0_acc: 0.7770 - val_Dense1_acc: 0.7590 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4825
Current time ....26.043
Epoch 2/10
 - 22s - loss: 23.8187 - Dense0_loss: 4.3023 - Dense1_loss: 4.2496 - Dense2_loss: 1.7285 - Dense3_loss: 6.7514 - Dense0_acc: 0.7294 - Dense1_acc: 0.7325 - Dense2_acc: 0.8922 - Dense3_acc: 0.5768 - val_loss: 25.9542 - val_Dense0_loss: 4.0134 - val_Dense1_loss: 6.5117 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.0352 - val_Dense0_acc: 0.7510 - val_Dense1_acc: 0.5960 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.5010
Current time ....48.249
Epoch 3/10
 - 23s - loss: 24.3258 - Dense0_loss: 4.4667 - Dense1_loss: 4.2144 - Dense2_loss: 1.7327 - Dense3_loss: 9.3039 - Dense0_acc: 0.7221 - Dense1_acc: 0.7376 - Dense2_acc: 0.8925 - Dense3_acc: 0.4218 - val_loss: 21.4636 - val_Dense0_loss: 3.9651 - val_Dense1_loss: 2.1967 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3566 - val_Dense0_acc: 0.7540 - val_Dense1_acc: 0.8635 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4195
Current time ....70.977
Epoch 4/10
 - 23s - loss: 20.7824 - Dense0_loss: 4.4018 - Dense1_loss: 2.2681 - Dense2_loss: 1.7327 - Dense3_loss: 9.4817 - Dense0_acc: 0.7265 - Dense1_acc: 0.8589 - Dense2_acc: 0.8925 - Dense3_acc: 0.4116 - val_loss: 22.7266 - val_Dense0_loss: 3.9328 - val_Dense1_loss: 2.3079 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3243 - val_Dense0_acc: 0.7560 - val_Dense1_acc: 0.8565 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4215
Current time ....93.753
Epoch 5/10
 - 23s - loss: 23.4378 - Dense0_loss: 4.9212 - Dense1_loss: 3.3991 - Dense2_loss: 1.7327 - Dense3_loss: 9.4992 - Dense0_acc: 0.6945 - Dense1_acc: 0.7885 - Dense2_acc: 0.8925 - Dense3_acc: 0.4105 - val_loss: 21.0261 - val_Dense0_loss: 4.1826 - val_Dense1_loss: 2.4208 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3082 - val_Dense0_acc: 0.7405 - val_Dense1_acc: 0.8490 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4225
Current time ....116.486
Epoch 6/10
 - 23s - loss: 22.2582 - Dense0_loss: 4.5812 - Dense1_loss: 3.3986 - Dense2_loss: 1.7327 - Dense3_loss: 9.4999 - Dense0_acc: 0.7156 - Dense1_acc: 0.7890 - Dense2_acc: 0.8925 - Dense3_acc: 0.4105 - val_loss: 24.5212 - val_Dense0_loss: 4.0804 - val_Dense1_loss: 6.5439 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3566 - val_Dense0_acc: 0.7465 - val_Dense1_acc: 0.5940 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4195
Current time ....139.283
Epoch 7/10
 - 23s - loss: 23.4563 - Dense0_loss: 5.5220 - Dense1_loss: 3.2572 - Dense2_loss: 1.7327 - Dense3_loss: 9.4887 - Dense0_acc: 0.6573 - Dense1_acc: 0.7975 - Dense2_acc: 0.8925 - Dense3_acc: 0.4113 - val_loss: 21.6862 - val_Dense0_loss: 3.9892 - val_Dense1_loss: 1.6199 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3566 - val_Dense0_acc: 0.7525 - val_Dense1_acc: 0.8995 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4195
Current time ....161.901
Epoch 8/10
 - 23s - loss: 23.4646 - Dense0_loss: 4.5653 - Dense1_loss: 3.6112 - Dense2_loss: 1.7334 - Dense3_loss: 9.5077 - Dense0_acc: 0.7165 - Dense1_acc: 0.7756 - Dense2_acc: 0.8924 - Dense3_acc: 0.4101 - val_loss: 22.0124 - val_Dense0_loss: 3.9570 - val_Dense1_loss: 2.4577 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3566 - val_Dense0_acc: 0.7545 - val_Dense1_acc: 0.8470 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4195
Current time ....184.642
Epoch 9/10
 - 23s - loss: 21.6506 - Dense0_loss: 4.5426 - Dense1_loss: 2.3417 - Dense2_loss: 1.7327 - Dense3_loss: 9.5077 - Dense0_acc: 0.7181 - Dense1_acc: 0.8546 - Dense2_acc: 0.8925 - Dense3_acc: 0.4101 - val_loss: 19.9844 - val_Dense0_loss: 4.2310 - val_Dense1_loss: 2.1034 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3566 - val_Dense0_acc: 0.7375 - val_Dense1_acc: 0.8695 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4195
Current time ....207.426
Epoch 10/10
 - 23s - loss: 19.8783 - Dense0_loss: 4.7468 - Dense1_loss: 2.0913 - Dense2_loss: 1.7327 - Dense3_loss: 9.5077 - Dense0_acc: 0.7055 - Dense1_acc: 0.8702 - Dense2_acc: 0.8925 - Dense3_acc: 0.4101 - val_loss: 19.0270 - val_Dense0_loss: 4.2675 - val_Dense1_loss: 2.0873 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3566 - val_Dense0_acc: 0.7350 - val_Dense1_acc: 0.8705 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4195
Current time ....230.268
Return:  <keras.callbacks.History object at 0x7f93cd0810f0>
239106
start time: 01:29:11
