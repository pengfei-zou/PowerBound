Importing candle utils for keras
Configuration file:  /home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/p3b3_default_model.txt
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'filter_sets': 3,
 'filter_sizes': 3,
 'learning_rate': 0.01,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'train_data': 'P3B3_data.tar.gz',
 'w_l2': 0.01,
 'wv_len': 300}
Params:
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'datatype': <class 'numpy.float32'>,
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'experiment_id': 'EXP000',
 'filter_sets': 3,
 'filter_sizes': 3,
 'gpus': [],
 'learning_rate': 0.01,
 'logfile': None,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'output_dir': '/home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/Output/EXP000/RUN000',
 'rng_seed': 7102,
 'run_id': 'RUN000',
 'shuffle': False,
 'timeout': -1,
 'train_bool': True,
 'train_data': 'P3B3_data.tar.gz',
 'verbose': None,
 'w_l2': 0.01,
 'wv_len': 300}
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input (InputLayer)              (None, 1500)         0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 1500, 300)    1396200     Input[0][0]                      
__________________________________________________________________________________________________
0_thfilter (Conv1D)             (None, 1500, 100)    90100       embedding[0][0]                  
__________________________________________________________________________________________________
1_thfilter (Conv1D)             (None, 1500, 100)    120100      embedding[0][0]                  
__________________________________________________________________________________________________
2_thfilter (Conv1D)             (None, 1500, 100)    150100      embedding[0][0]                  
__________________________________________________________________________________________________
global_max_pooling1d_1 (GlobalM (None, 100)          0           0_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_2 (GlobalM (None, 100)          0           1_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_3 (GlobalM (None, 100)          0           2_thfilter[0][0]                 
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 300)          0           global_max_pooling1d_1[0][0]     
                                                                 global_max_pooling1d_2[0][0]     
                                                                 global_max_pooling1d_3[0][0]     
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 300)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
Dense0 (Dense)                  (None, 6)            1806        dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense1 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense2 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense3 (Dense)                  (None, 3)            903         dropout_1[0][0]                  
==================================================================================================
Total params: 1,760,413
Trainable params: 1,760,413
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 8000 samples, validate on 2000 samples
Epoch 1/10
 - 21s - loss: 16.2136 - Dense0_loss: 2.3526 - Dense1_loss: 1.1877 - Dense2_loss: 1.1875 - Dense3_loss: 3.2712 - Dense0_acc: 0.7450 - Dense1_acc: 0.8467 - Dense2_acc: 0.8819 - Dense3_acc: 0.6101 - val_loss: 27.9683 - val_Dense0_loss: 3.8393 - val_Dense1_loss: 6.5473 - val_Dense2_loss: 1.8951 - val_Dense3_loss: 6.1131 - val_Dense0_acc: 0.7590 - val_Dense1_acc: 0.5790 - val_Dense2_acc: 0.8805 - val_Dense3_acc: 0.6030
Current time ....20.891
Epoch 2/10
 - 17s - loss: 23.4400 - Dense0_loss: 4.7236 - Dense1_loss: 2.8288 - Dense2_loss: 1.7223 - Dense3_loss: 8.0719 - Dense0_acc: 0.7029 - Dense1_acc: 0.8209 - Dense2_acc: 0.8920 - Dense3_acc: 0.4956 - val_loss: 20.1901 - val_Dense0_loss: 3.9930 - val_Dense1_loss: 2.1605 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 7.4657 - val_Dense0_acc: 0.7515 - val_Dense1_acc: 0.8650 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.5280
Current time ....38.338
Epoch 3/10
 - 18s - loss: 22.5618 - Dense0_loss: 4.8469 - Dense1_loss: 2.8566 - Dense2_loss: 1.7336 - Dense3_loss: 8.7446 - Dense0_acc: 0.6983 - Dense1_acc: 0.8212 - Dense2_acc: 0.8924 - Dense3_acc: 0.4556 - val_loss: 26.7323 - val_Dense0_loss: 4.8310 - val_Dense1_loss: 6.1367 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.1881 - val_Dense0_acc: 0.7000 - val_Dense1_acc: 0.6170 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4885
Current time ....55.863
Epoch 4/10
 - 18s - loss: 24.5702 - Dense0_loss: 5.3301 - Dense1_loss: 3.9103 - Dense2_loss: 1.7327 - Dense3_loss: 7.6746 - Dense0_acc: 0.6689 - Dense1_acc: 0.7565 - Dense2_acc: 0.8925 - Dense3_acc: 0.5229 - val_loss: 21.1984 - val_Dense0_loss: 4.1182 - val_Dense1_loss: 1.8060 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.1638 - val_Dense0_acc: 0.7445 - val_Dense1_acc: 0.8875 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4935
Current time ....73.399
Epoch 5/10
 - 17s - loss: 22.7678 - Dense0_loss: 5.1530 - Dense1_loss: 2.8687 - Dense2_loss: 1.7327 - Dense3_loss: 8.2128 - Dense0_acc: 0.6799 - Dense1_acc: 0.8216 - Dense2_acc: 0.8925 - Dense3_acc: 0.4900 - val_loss: 21.8113 - val_Dense0_loss: 4.1101 - val_Dense1_loss: 3.6158 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 7.5210 - val_Dense0_acc: 0.7450 - val_Dense1_acc: 0.7755 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.5330
Current time ....90.887
Epoch 6/10
 - 18s - loss: 22.9246 - Dense0_loss: 5.3642 - Dense1_loss: 3.4310 - Dense2_loss: 1.7327 - Dense3_loss: 7.7565 - Dense0_acc: 0.6670 - Dense1_acc: 0.7865 - Dense2_acc: 0.8925 - Dense3_acc: 0.5183 - val_loss: 22.9489 - val_Dense0_loss: 5.6088 - val_Dense1_loss: 2.0954 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 7.3121 - val_Dense0_acc: 0.6520 - val_Dense1_acc: 0.8700 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.5450
Current time ....108.401
Epoch 7/10
 - 17s - loss: 22.9096 - Dense0_loss: 5.5531 - Dense1_loss: 2.4104 - Dense2_loss: 1.7327 - Dense3_loss: 8.4133 - Dense0_acc: 0.6553 - Dense1_acc: 0.8504 - Dense2_acc: 0.8925 - Dense3_acc: 0.4776 - val_loss: 24.0162 - val_Dense0_loss: 5.7783 - val_Dense1_loss: 3.5135 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.6415 - val_Dense1_acc: 0.7815 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....125.867
Epoch 8/10
 - 17s - loss: 21.3713 - Dense0_loss: 4.9441 - Dense1_loss: 2.7885 - Dense2_loss: 1.7327 - Dense3_loss: 8.2718 - Dense0_acc: 0.6930 - Dense1_acc: 0.8269 - Dense2_acc: 0.8925 - Dense3_acc: 0.4866 - val_loss: 19.7267 - val_Dense0_loss: 4.5453 - val_Dense1_loss: 2.1276 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 7.8656 - val_Dense0_acc: 0.7180 - val_Dense1_acc: 0.8680 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.5120
Current time ....143.357
Epoch 9/10
 - 17s - loss: 21.5309 - Dense0_loss: 4.7042 - Dense1_loss: 2.7028 - Dense2_loss: 1.7344 - Dense3_loss: 8.2318 - Dense0_acc: 0.7080 - Dense1_acc: 0.8322 - Dense2_acc: 0.8924 - Dense3_acc: 0.4890 - val_loss: 19.9121 - val_Dense0_loss: 4.3438 - val_Dense1_loss: 2.2324 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 7.8576 - val_Dense0_acc: 0.7305 - val_Dense1_acc: 0.8615 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.5125
Current time ....160.815
Epoch 10/10
 - 17s - loss: 19.6556 - Dense0_loss: 4.4969 - Dense1_loss: 2.4137 - Dense2_loss: 1.7327 - Dense3_loss: 8.3040 - Dense0_acc: 0.7210 - Dense1_acc: 0.8502 - Dense2_acc: 0.8925 - Dense3_acc: 0.4848 - val_loss: 19.7777 - val_Dense0_loss: 4.3438 - val_Dense1_loss: 2.2162 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.7305 - val_Dense1_acc: 0.8625 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....178.294
Return:  <keras.callbacks.History object at 0x7f92606ae0f0>
186871
start time: 00:53:20
