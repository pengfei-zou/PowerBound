Importing candle utils for keras
Configuration file:  /home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/p3b3_default_model.txt
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'filter_sets': 3,
 'filter_sizes': 3,
 'learning_rate': 0.01,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'train_data': 'P3B3_data.tar.gz',
 'w_l2': 0.01,
 'wv_len': 300}
Params:
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'datatype': <class 'numpy.float32'>,
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'experiment_id': 'EXP000',
 'filter_sets': 3,
 'filter_sizes': 3,
 'gpus': [],
 'learning_rate': 0.01,
 'logfile': None,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'output_dir': '/home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/Output/EXP000/RUN000',
 'rng_seed': 7102,
 'run_id': 'RUN000',
 'shuffle': False,
 'timeout': -1,
 'train_bool': True,
 'train_data': 'P3B3_data.tar.gz',
 'verbose': None,
 'w_l2': 0.01,
 'wv_len': 300}
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input (InputLayer)              (None, 1500)         0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 1500, 300)    1396200     Input[0][0]                      
__________________________________________________________________________________________________
0_thfilter (Conv1D)             (None, 1500, 100)    90100       embedding[0][0]                  
__________________________________________________________________________________________________
1_thfilter (Conv1D)             (None, 1500, 100)    120100      embedding[0][0]                  
__________________________________________________________________________________________________
2_thfilter (Conv1D)             (None, 1500, 100)    150100      embedding[0][0]                  
__________________________________________________________________________________________________
global_max_pooling1d_1 (GlobalM (None, 100)          0           0_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_2 (GlobalM (None, 100)          0           1_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_3 (GlobalM (None, 100)          0           2_thfilter[0][0]                 
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 300)          0           global_max_pooling1d_1[0][0]     
                                                                 global_max_pooling1d_2[0][0]     
                                                                 global_max_pooling1d_3[0][0]     
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 300)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
Dense0 (Dense)                  (None, 6)            1806        dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense1 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense2 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense3 (Dense)                  (None, 3)            903         dropout_1[0][0]                  
==================================================================================================
Total params: 1,760,413
Trainable params: 1,760,413
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 8000 samples, validate on 2000 samples
Epoch 1/10
 - 19s - loss: 18.3318 - Dense0_loss: 3.0093 - Dense1_loss: 1.8422 - Dense2_loss: 1.1987 - Dense3_loss: 4.9614 - Dense0_acc: 0.7311 - Dense1_acc: 0.8227 - Dense2_acc: 0.8957 - Dense3_acc: 0.5565 - val_loss: 22.1771 - val_Dense0_loss: 3.4291 - val_Dense1_loss: 1.7434 - val_Dense2_loss: 1.9136 - val_Dense3_loss: 6.5225 - val_Dense0_acc: 0.7780 - val_Dense1_acc: 0.8820 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.5840
Current time ....18.945
Epoch 2/10
 - 16s - loss: 24.6697 - Dense0_loss: 5.0513 - Dense1_loss: 3.2149 - Dense2_loss: 1.7345 - Dense3_loss: 7.8054 - Dense0_acc: 0.6835 - Dense1_acc: 0.7969 - Dense2_acc: 0.8919 - Dense3_acc: 0.5131 - val_loss: 21.7068 - val_Dense0_loss: 4.0763 - val_Dense1_loss: 2.8790 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.4613 - val_Dense0_acc: 0.7470 - val_Dense1_acc: 0.8200 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4735
Current time ....34.572
Epoch 3/10
 - 16s - loss: 23.0890 - Dense0_loss: 4.9902 - Dense1_loss: 3.7421 - Dense2_loss: 1.7327 - Dense3_loss: 8.8067 - Dense0_acc: 0.6900 - Dense1_acc: 0.7669 - Dense2_acc: 0.8925 - Dense3_acc: 0.4530 - val_loss: 28.6549 - val_Dense0_loss: 4.2874 - val_Dense1_loss: 9.2034 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3566 - val_Dense0_acc: 0.7340 - val_Dense1_acc: 0.4290 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4195
Current time ....50.368
Epoch 4/10
 - 16s - loss: 22.1566 - Dense0_loss: 4.6116 - Dense1_loss: 3.5069 - Dense2_loss: 1.7327 - Dense3_loss: 9.5117 - Dense0_acc: 0.7138 - Dense1_acc: 0.7817 - Dense2_acc: 0.8925 - Dense3_acc: 0.4099 - val_loss: 19.6609 - val_Dense0_loss: 4.2874 - val_Dense1_loss: 1.8952 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3566 - val_Dense0_acc: 0.7340 - val_Dense1_acc: 0.8820 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4195
Current time ....66.157
Epoch 5/10
 - 16s - loss: 21.9197 - Dense0_loss: 5.0376 - Dense1_loss: 2.5005 - Dense2_loss: 1.7327 - Dense3_loss: 9.5050 - Dense0_acc: 0.6873 - Dense1_acc: 0.8441 - Dense2_acc: 0.8925 - Dense3_acc: 0.4103 - val_loss: 21.8428 - val_Dense0_loss: 4.9136 - val_Dense1_loss: 1.9756 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3566 - val_Dense0_acc: 0.6950 - val_Dense1_acc: 0.8770 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4195
Current time ....81.944
Epoch 6/10
 - 16s - loss: 24.1838 - Dense0_loss: 5.2627 - Dense1_loss: 4.9660 - Dense2_loss: 1.7327 - Dense3_loss: 9.5117 - Dense0_acc: 0.6734 - Dense1_acc: 0.6916 - Dense2_acc: 0.8925 - Dense3_acc: 0.4099 - val_loss: 23.4660 - val_Dense0_loss: 4.5534 - val_Dense1_loss: 5.7205 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3566 - val_Dense0_acc: 0.7175 - val_Dense1_acc: 0.6445 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4195
Current time ....97.741
Epoch 7/10
 - 16s - loss: 22.0932 - Dense0_loss: 4.6052 - Dense1_loss: 3.2912 - Dense2_loss: 1.7327 - Dense3_loss: 9.5097 - Dense0_acc: 0.7138 - Dense1_acc: 0.7955 - Dense2_acc: 0.8925 - Dense3_acc: 0.4100 - val_loss: 22.8310 - val_Dense0_loss: 4.2713 - val_Dense1_loss: 2.4926 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3566 - val_Dense0_acc: 0.7350 - val_Dense1_acc: 0.8450 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4195
Current time ....113.506
Epoch 8/10
 - 16s - loss: 22.8681 - Dense0_loss: 4.6610 - Dense1_loss: 3.4764 - Dense2_loss: 1.7327 - Dense3_loss: 9.5077 - Dense0_acc: 0.7108 - Dense1_acc: 0.7841 - Dense2_acc: 0.8925 - Dense3_acc: 0.4101 - val_loss: 21.5777 - val_Dense0_loss: 4.2874 - val_Dense1_loss: 2.5950 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3566 - val_Dense0_acc: 0.7340 - val_Dense1_acc: 0.8390 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4195
Current time ....129.279
Epoch 9/10
 - 16s - loss: 21.4446 - Dense0_loss: 4.4023 - Dense1_loss: 3.2385 - Dense2_loss: 1.7327 - Dense3_loss: 9.5036 - Dense0_acc: 0.7269 - Dense1_acc: 0.7989 - Dense2_acc: 0.8925 - Dense3_acc: 0.4104 - val_loss: 20.2769 - val_Dense0_loss: 4.3277 - val_Dense1_loss: 1.7415 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3566 - val_Dense0_acc: 0.7315 - val_Dense1_acc: 0.8915 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4195
Current time ....145.068
Epoch 10/10
 - 16s - loss: 24.5554 - Dense0_loss: 5.2275 - Dense1_loss: 4.9524 - Dense2_loss: 1.7327 - Dense3_loss: 9.5117 - Dense0_acc: 0.6756 - Dense1_acc: 0.6925 - Dense2_acc: 0.8925 - Dense3_acc: 0.4099 - val_loss: 27.9164 - val_Dense0_loss: 4.5856 - val_Dense1_loss: 9.4049 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 9.3566 - val_Dense0_acc: 0.7155 - val_Dense1_acc: 0.4165 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4195
Current time ....160.859
Return:  <keras.callbacks.History object at 0x7f5f7a07fdd8>
170120
start time: 04:13:57
