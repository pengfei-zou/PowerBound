Importing candle utils for keras
Configuration file:  /home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/p3b3_default_model.txt
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'filter_sets': 3,
 'filter_sizes': 3,
 'learning_rate': 0.01,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'train_data': 'P3B3_data.tar.gz',
 'w_l2': 0.01,
 'wv_len': 300}
Params:
{'batch_size': 10,
 'data_url': 'ftp://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot3/',
 'datatype': <class 'numpy.float32'>,
 'dropout': 0.5,
 'emb_l2': 0.001,
 'epochs': 10,
 'experiment_id': 'EXP000',
 'filter_sets': 3,
 'filter_sizes': 3,
 'gpus': [],
 'learning_rate': 0.01,
 'logfile': None,
 'model_name': 'p3b3',
 'num_filters': 100,
 'optimizer': 'adam',
 'output_dir': '/home/pzou/software/software-benchmark/Deep_Learning_Bench/Candle/Pilot3/P3B3/Output/EXP000/RUN000',
 'rng_seed': 7102,
 'run_id': 'RUN000',
 'shuffle': False,
 'timeout': -1,
 'train_bool': True,
 'train_data': 'P3B3_data.tar.gz',
 'verbose': None,
 'w_l2': 0.01,
 'wv_len': 300}
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input (InputLayer)              (None, 1500)         0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 1500, 300)    1396200     Input[0][0]                      
__________________________________________________________________________________________________
0_thfilter (Conv1D)             (None, 1500, 100)    90100       embedding[0][0]                  
__________________________________________________________________________________________________
1_thfilter (Conv1D)             (None, 1500, 100)    120100      embedding[0][0]                  
__________________________________________________________________________________________________
2_thfilter (Conv1D)             (None, 1500, 100)    150100      embedding[0][0]                  
__________________________________________________________________________________________________
global_max_pooling1d_1 (GlobalM (None, 100)          0           0_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_2 (GlobalM (None, 100)          0           1_thfilter[0][0]                 
__________________________________________________________________________________________________
global_max_pooling1d_3 (GlobalM (None, 100)          0           2_thfilter[0][0]                 
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 300)          0           global_max_pooling1d_1[0][0]     
                                                                 global_max_pooling1d_2[0][0]     
                                                                 global_max_pooling1d_3[0][0]     
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 300)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
Dense0 (Dense)                  (None, 6)            1806        dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense1 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense2 (Dense)                  (None, 2)            602         dropout_1[0][0]                  
__________________________________________________________________________________________________
Dense3 (Dense)                  (None, 3)            903         dropout_1[0][0]                  
==================================================================================================
Total params: 1,760,413
Trainable params: 1,760,413
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 8000 samples, validate on 2000 samples
Epoch 1/10
 - 22s - loss: 17.5242 - Dense0_loss: 2.4992 - Dense1_loss: 1.4814 - Dense2_loss: 1.0357 - Dense3_loss: 3.4311 - Dense0_acc: 0.7450 - Dense1_acc: 0.8387 - Dense2_acc: 0.8994 - Dense3_acc: 0.6199 - val_loss: 24.6898 - val_Dense0_loss: 3.9232 - val_Dense1_loss: 1.6748 - val_Dense2_loss: 1.9132 - val_Dense3_loss: 7.0839 - val_Dense0_acc: 0.7535 - val_Dense1_acc: 0.8835 - val_Dense2_acc: 0.8790 - val_Dense3_acc: 0.5485
Current time ....22.370
Epoch 2/10
 - 19s - loss: 23.4562 - Dense0_loss: 4.1941 - Dense1_loss: 2.2859 - Dense2_loss: 1.7296 - Dense3_loss: 8.1345 - Dense0_acc: 0.7359 - Dense1_acc: 0.8532 - Dense2_acc: 0.8917 - Dense3_acc: 0.4914 - val_loss: 22.3065 - val_Dense0_loss: 4.0338 - val_Dense1_loss: 2.0597 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.8891 - val_Dense0_acc: 0.7495 - val_Dense1_acc: 0.8715 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4485
Current time ....41.241
Epoch 3/10
 - 19s - loss: 21.3189 - Dense0_loss: 4.6718 - Dense1_loss: 2.5084 - Dense2_loss: 1.7327 - Dense3_loss: 8.6504 - Dense0_acc: 0.7095 - Dense1_acc: 0.8431 - Dense2_acc: 0.8925 - Dense3_acc: 0.4633 - val_loss: 20.1887 - val_Dense0_loss: 4.0798 - val_Dense1_loss: 2.2576 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.7465 - val_Dense1_acc: 0.8590 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....59.961
Epoch 4/10
 - 19s - loss: 21.3930 - Dense0_loss: 4.3216 - Dense1_loss: 3.7307 - Dense2_loss: 1.7327 - Dense3_loss: 8.6514 - Dense0_acc: 0.7316 - Dense1_acc: 0.7677 - Dense2_acc: 0.8925 - Dense3_acc: 0.4633 - val_loss: 22.0641 - val_Dense0_loss: 5.4323 - val_Dense1_loss: 2.1598 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.6625 - val_Dense1_acc: 0.8660 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....78.769
Epoch 5/10
 - 19s - loss: 21.6861 - Dense0_loss: 5.2026 - Dense1_loss: 2.4712 - Dense2_loss: 1.7357 - Dense3_loss: 8.6475 - Dense0_acc: 0.6768 - Dense1_acc: 0.8459 - Dense2_acc: 0.8922 - Dense3_acc: 0.4634 - val_loss: 20.6203 - val_Dense0_loss: 4.2790 - val_Dense1_loss: 2.2404 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.7345 - val_Dense1_acc: 0.8610 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....97.689
Epoch 6/10
 - 19s - loss: 20.9302 - Dense0_loss: 5.5163 - Dense1_loss: 2.7850 - Dense2_loss: 1.7327 - Dense3_loss: 8.6514 - Dense0_acc: 0.6578 - Dense1_acc: 0.8270 - Dense2_acc: 0.8925 - Dense3_acc: 0.4633 - val_loss: 23.9980 - val_Dense0_loss: 6.0169 - val_Dense1_loss: 5.1439 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.6265 - val_Dense1_acc: 0.6795 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....116.641
Epoch 7/10
 - 19s - loss: 19.7704 - Dense0_loss: 4.7088 - Dense1_loss: 2.6518 - Dense2_loss: 1.7327 - Dense3_loss: 8.6514 - Dense0_acc: 0.7075 - Dense1_acc: 0.8352 - Dense2_acc: 0.8925 - Dense3_acc: 0.4633 - val_loss: 18.7708 - val_Dense0_loss: 4.2068 - val_Dense1_loss: 1.9019 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.7390 - val_Dense1_acc: 0.8820 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....135.621
Epoch 8/10
 - 19s - loss: 18.4829 - Dense0_loss: 4.3035 - Dense1_loss: 2.3171 - Dense2_loss: 1.7327 - Dense3_loss: 8.6514 - Dense0_acc: 0.7330 - Dense1_acc: 0.8561 - Dense2_acc: 0.8925 - Dense3_acc: 0.4633 - val_loss: 18.2063 - val_Dense0_loss: 4.2336 - val_Dense1_loss: 1.8778 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.7370 - val_Dense1_acc: 0.8835 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....154.576
Epoch 9/10
 - 19s - loss: 19.8448 - Dense0_loss: 4.5865 - Dense1_loss: 2.3406 - Dense2_loss: 1.7327 - Dense3_loss: 8.6514 - Dense0_acc: 0.7154 - Dense1_acc: 0.8544 - Dense2_acc: 0.8925 - Dense3_acc: 0.4633 - val_loss: 19.8729 - val_Dense0_loss: 4.3438 - val_Dense1_loss: 2.0876 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.7305 - val_Dense1_acc: 0.8705 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....173.443
Epoch 10/10
 - 19s - loss: 19.4180 - Dense0_loss: 4.7363 - Dense1_loss: 2.2590 - Dense2_loss: 1.7327 - Dense3_loss: 8.6514 - Dense0_acc: 0.7061 - Dense1_acc: 0.8596 - Dense2_acc: 0.8925 - Dense3_acc: 0.4633 - val_loss: 20.9419 - val_Dense0_loss: 5.2746 - val_Dense1_loss: 2.4177 - val_Dense2_loss: 1.9342 - val_Dense3_loss: 8.9133 - val_Dense0_acc: 0.6720 - val_Dense1_acc: 0.8500 - val_Dense2_acc: 0.8800 - val_Dense3_acc: 0.4470
Current time ....192.397
Return:  <keras.callbacks.History object at 0x7f83ba45add8>
201098
start time: 04:42:00
