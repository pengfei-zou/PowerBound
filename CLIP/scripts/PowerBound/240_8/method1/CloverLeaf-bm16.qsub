#!/bin/bash

#PBS -N CloverLeaf_16
#PBS -l nodes=n01+n02+n03+n04+n05+n06+n07+n08,walltime=01:00:00


power_cpu=108
power_mem=18

nodes=`cat $PBS_NODEFILE | sort | uniq`

util_dir=/usr/local/bin
file_dir=/home/pzou/projects/haswell/multi_node/cluster2017
software_dir=/home/pzou/software/software-benchmark/


module purge
#module load gcc-6.2.0 //it doesn't fit well gcc-6.2.0
module load openmpi-2.0.1

export OMP_NUM_THREADS=24
export GOMP_CPU_AFFINITY="0-11,12-23"

power_bound=240_8
method=method1

export bench="CloverLeaf16"
export bench_code="Cloverleaf-bm16-8-$OMP_NUM_THREADS"


export job_dir=$file_dir/$power_bound/$method/$bench/$PBS_JOBID
mkdir -p $job_dir

#set power capping
for node in $nodes; do
    ssh $node "$util_dir/mu_power_gadget -p $power_cpu >/dev/null &" &
    ssh $node "$util_dir/mu_power_gadget -r $power_mem >/dev/null &" &
done

# run experiments
for i in $(seq 1 3); do
    echo "run #1: $i"
    mkdir -p $job_dir/$i
    sleep 5
    # start power logs
    for node in $nodes; do
        ssh $node "$util_dir/rapl -s 0.1 -c 0,12 -f $job_dir/$i/$bench_code-$node-pwr.log &" &
    done

    t0=$(date +%s%N)
    echo "starting $bench_code run $i at $t0"

	cd $software_dir/
	cp CloverLeaf_ref/InputDecks/clover_bm16.in clover.in
    # run jobs
    mpirun -n 8 CloverLeaf_ref/clover_leaf
    t1=$(date +%s%N)

	cp clover.out $job_dir/$i/$bench_code-perf.txt
    # close power logs
    for node in $nodes; do
        ssh $node "pkill rapl"
    done

    t1=$(date +%s%N)
    echo "finishing $bench_code run $i at $t1"
done

# remove power capping
for node in $nodes; do
    ssh $node "$util_dir/mu_power_gadget -p 200" 
    ssh $node "$util_dir/mu_power_gadget -r 100" 
done